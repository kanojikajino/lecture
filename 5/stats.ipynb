{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 応用計量分析２（第5回）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 担当教員: 梶野 洸（かじの ひろし）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本日の目標\n",
    "\n",
    "- 確率・統計を思い出す\n",
    "- オブジェクト指向の書き方で最尤推定してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率変数\n",
    "\n",
    "決定的には定まらない観測値をモデル化するのに用いる\n",
    "\n",
    "- 例1: サイコロを振って出る目\n",
    "    - $X_n\\in\\{1,2,\\dots,6\\}$: $n$回目に出た目\n",
    "    - 1~6の目のどれが出るかわからない\n",
    "- 例2: 私の身長 $X_n\\in\\mathbb{R}_+$\n",
    "    - $X_n$: $n$回目の測定値\n",
    "    - 測るたびに微妙に値が異なる（測定誤差）\n",
    "- 例3: 人類の身長 $X_n\\in\\mathbb{R}_+$\n",
    "    - $X_n$: $n$人目の測定値\n",
    "    - 人によって身長は異なる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さいころを振る前にも各回で出る目を確率変数として書ける\n",
    "\n",
    "<img src=\"figs/rv.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$ 回振るとそれぞれの確率変数の観測値が得られる\n",
    "\n",
    "<img src=\"figs/rv_obs.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試行のたびに得られる観測値は変わる\n",
    "\n",
    "<img src=\"figs/rv_obs1.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計でやりたいこと\n",
    "\n",
    "得られた観測値から、確率変数の従う規則を推測したい\n",
    "\n",
    "- 得られた観測値 = $N$回さいころを振ったときに $\\{1,5,\\dots,2\\}$ という目が出た"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率変数の従う規則=確率分布\n",
    "\n",
    "- $p(X)$: 確率変数 $X$ の従う分布\n",
    "    - 観測値を入力すると確率を返す関数\n",
    "    - 例えば $p(x)=1/6~(\\forall x\\in\\{1,2,\\dots,6\\}$) だとすべての目が1/6の確率で出る、ということを表す\n",
    "    - 未知のパラメタを用意しておいて、それを観測値から決定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率変数の従う規則は色々な決め方がある\n",
    "\n",
    "事前知識や、手元にあるデータから推定できるか否か、という観点で選ぶ\n",
    "\n",
    "1. 何回目に振ったかは関係なく、すべての目は同一の分布 $p(X)$ に独立に従う（だいたいこれ）\n",
    "1. 奇数回目は $p_o(X)$, 偶数回目は $p_e(X)$ に独立に従う\n",
    "1. 回数や過去の履歴に依存して目が決まる。つまり $p(X_1, X_2,\\dots, X_N)$ に従う。\n",
    "    - $N$ 回振るという試行を何回もやっているならこの分布は推定可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計でやりたいこと\n",
    "\n",
    "得られた観測値から、確率変数の従う規則を推測したい\n",
    "\n",
    "- 得られた観測値 = $N$回さいころを振ったときに $\\{1,5,\\dots,2\\}$ という目が出た\n",
    "- 仮定する確率分布（の一例）: すべての目は同一の分布 $p(X; \\pi)$ に独立に従う\n",
    "    - $p(X=k;\\pi) = \\pi_k~(k=1,2,\\dots,6)$ という分布（多項分布）\n",
    "    - $\\pi$ を未知なものとして、データから決めたい！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/model_class.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率モデルのパラメタの決め方\n",
    "\n",
    "- 最尤推定\n",
    "    -  手持ちのサンプルが得られる確率が最大になるようにパラメタを定める\n",
    "    - 気持ち: 手持ちのデータが出てくる確率が高くなかったらどのデータの確率が高いんだ！？\n",
    "- ベイズ推定\n",
    "    - 推定したいパラメタに事前分布 $p(\\theta)$ を置き、サンプルが得られた元での事後分布 $p(\\theta \\mid \\mathcal{D})$ を計算する\n",
    "    - 事前分布は固定\n",
    "    - 気持ち: サンプルで条件付けを行うとパラメタの範囲がそれっぽいところに狭まる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最尤推定\n",
    "\n",
    "- モデルの集合: $\\mathcal{M} = \\{p(X; \\theta) \\mid \\theta \\in \\Theta\\}$\n",
    "- サンプル: $\\mathcal{D}=\\{x_1,\\dots, x_N\\}$\n",
    "    - __独立に同じ分布に従っていると仮定__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サンプル $\\mathcal{D}$ が得られる確率は\n",
    "$$\n",
    "\\ell(\\theta) = p(\\mathcal{D} ; \\theta) = \\prod_{n=1}^N p(x_n;\\theta)\n",
    "$$\n",
    "（独立に同じ分布に従っていると仮定したため）\n",
    "\n",
    "- $\\theta$ の関数$\\ell(\\theta)$としてみることができる\n",
    "- この時、$\\ell(\\theta)$ を尤度と呼ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最尤推定量 $\\hat{\\theta}$ は\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\max_{\\theta} \\ell(\\theta) = \\arg\\max_{\\theta}\\prod_{n=1}^N p(x_n; \\theta)\n",
    "$$\n",
    "と定義される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし計算の簡単のため＆実装上の問題から負の対数尤度\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = - \\log \\ell(\\theta) = -\\sum_{n=1}^N \\log p(x_n;\\theta)\n",
    "$$\n",
    "を使うことが多い。\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\max_{\\theta} \\ell(\\theta) = \\arg\\min_{\\theta} \\mathcal{L}(\\theta)\n",
    "$$\n",
    "であることに注意。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# なぜ負の対数尤度を使うか\n",
    "\n",
    "- 対数尤度を使う理由\n",
    "    - 掛け算がたし算になる（微分するのが楽になる）\n",
    "    - 対数を取ると小さな値でもコンピュータで扱いやすい（丸め誤差が乗りにくい）\n",
    "- 特に負の対数を使う理由（強いて言えば...）\n",
    "    - 最適化問題は minimize の形で書かれることが多い\n",
    "    - 情報理論的な解釈（負の対数尤度は、データを送るのに必要なビット数に相当する）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最尤推定まとめ\n",
    "\n",
    "1. サンプルが得られる確率（≒尤度）を書き下す\n",
    "1. 負の対数をとって、負の対数尤度を書き下す\n",
    "1. 負の対数尤度が最小になるパラメタ $\\hat{\\theta}$ を求める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計モデルを用いた解析の流れ\n",
    "\n",
    "1. 確率変数を定める（どの量に対する確率分布が欲しいか？）\n",
    "1. 確率変数の観測値と確率分布の関係を仮定する（すべての観測値が独立同一分布に従う、など）\n",
    "1. 確率分布の集合を仮定する（正規分布、多項分布、など）\n",
    "1. 確率分布の集合から良さげなものを取ってくる（最尤推定、ベイズ推定、など）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計モデルの実装\n",
    "オブジェクト指向の技法で実装することが多い\n",
    "\n",
    "- オブジェクト指向とは？\n",
    "- Python ではどうやるの？\n",
    "- 結局どうすればいいのか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オブジェクト指向プログラミング\n",
    "\n",
    "- （とても雑にいうと）オブジェクト単位でプログラムを考える技法\n",
    "    - クラス ≒ 設計図\n",
    "    - オブジェクト = クラスの設計図に従って作られたもの"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- クラスはオブジェクトの内部状態やオブジェクトに対して使える命令を規定する\n",
    "- あるクラスから作られたオブジェクトは、\n",
    "    - オブジェクト固有の内部状態の値を持つ\n",
    "    - クラスで規定された命令を使える\n",
    "\n",
    "<img src=\"figs/oop.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロボットをクラスを使って書いてみる\n",
    "\n",
    "class Robot: # 以下の一段下がっているところがクラス\n",
    "    def __init__(self, state, memory): # 初期状態を与えたときにオブジェクトを作る関数（名前が __init__ と決まっている）\n",
    "        '''\n",
    "        self = オブジェクトを指す。 self.state は、オブジェクトの state という変数を指す。\n",
    "        下の命令は、 self.state に state の値を代入することを表す\n",
    "        '''\n",
    "        self.state = state\n",
    "        self.memory = memory\n",
    "\n",
    "    def stand_up(self): # オブジェクトへの命令の引数には必ず self を入れる\n",
    "        self.state = 'stand up' # 内部状態を更新できる\n",
    "        \n",
    "    def sit_down(self):\n",
    "        self.state = 'sit down'\n",
    "    \n",
    "    def memorize(self, memory): # オブジェクトへ命令する際に、引数を渡すこともできる\n",
    "        self.memory = memory\n",
    "        \n",
    "    def get_state(self): \n",
    "        return self.state\n",
    " \n",
    "    def get_memory(self):\n",
    "        return self.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_robot_1 = Robot('sleep', 'nothing') # クラス名(__init__の引数) と書くとそのクラスのオブジェクトが生成される\n",
    "print(my_robot_1.get_state()) # オブジェクト.メソッド名(selfを省略した引数たち) と書くと、オブジェクトに命令できる\n",
    "print(my_robot_1.get_memory()) # 初期化に用いた状態がセットされている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_robot_1.stand_up() # 内部状態が更新される\n",
    "print(my_robot_1.get_state()) \n",
    "my_robot_1.memorize('餃子を食べたい') # 内部状態が更新される\n",
    "print(my_robot_1.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_robot_1 = Robot('stand up', 'nothing')\n",
    "my_robot_2 = Robot('sleep', 'ラーメン食べたい')\n",
    "my_robot_1.sit_down() # ロボット1の状態を変えてもロボット2の状態には影響を与えない\n",
    "print(my_robot_1.get_state())\n",
    "print(my_robot_2.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習に当てはめてみると\n",
    "- クラス=モデル\n",
    "    - 内部状態 = パラメタ\n",
    "    - 命令 = モデルの推定方法\n",
    "- オブジェクト\n",
    "    - 具体的なパラメタの値を持ったモデル\n",
    "    - データを使ってモデルを推定して内部状態を変える\n",
    "    - 推定し終わった内部状態で予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/oop_gauss.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/oop_logistic.png\" width=1024px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "正規分布の場合、\n",
    "\n",
    "- 内部状態\n",
    "- 欲しい命令\n",
    "\n",
    "は何か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一つの答え\n",
    "\n",
    "- 内部状態\n",
    "    - 平均\n",
    "    - 分散共分散行列\n",
    "- 命令\n",
    "    - データを入力して、パラメタを最尤推定する\n",
    "    - データを入力して、各データの確率密度を計算する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 他の答え\n",
    "補助的なものを持っていてもよい\n",
    "\n",
    "- 内部状態\n",
    "    - 平均\n",
    "    - 分散共分散行列\n",
    "    - __次元__\n",
    "- 命令\n",
    "    - データを入力して、パラメタを最尤推定する\n",
    "    - データを入力して、各データの確率密度を計算する\n",
    "    - __入力の次元のチェック__\n",
    "    - __内部状態の更新__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バグに気付きやすくするために（後述）\n",
    "\n",
    "- 入力のチェックを行う\n",
    "    - 想定外のことが起こったらエラーを吐くようにする\n",
    "- 内部状態の更新はメソッドを使う\n",
    "    - 想定外の内部状態にならないようにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python での実装\n",
    "\n",
    "まずは正規分布クラスを実装してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Gaussian:\n",
    "    def __init__(self, dim):\n",
    "        '''コンストラクタ（みたいなもの）\n",
    "        オブジェクトを作るときに初めに実行される。\n",
    "        内部状態の初期化に使う\n",
    "        '''\n",
    "        self.dim = dim\n",
    "        '''\n",
    "        self = オブジェクトを指す。 self.dim は、オブジェクトの dim という変数を指す。\n",
    "        上の命令は、 self.dim に dim の値を代入することを表す\n",
    "        '''\n",
    "        self.set_mean(np.random.randn(dim)) # オブジェクトの mean という変数をランダムに初期化\n",
    "        self.set_cov(np.identity(dim))\n",
    "        \n",
    "    def log_pdf(self, X):\n",
    "        ''' 確率密度関数の対数を返す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        log_pdf : array, shape (sample_size,)\n",
    "        '''\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def fit(self, X):\n",
    "        ''' X を使って最尤推定をする\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        ''' 現状のパラメタを使って `sample_size` のサイズのサンプルを生成する\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        sample_size : int\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "            各行は平均 `self.mean`, 分散 `self.cov` の正規分布に従う\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def set_mean(self, mean):\n",
    "        if mean.shape != (self.dim,): # 間違ったサイズの配列で内部状態を更新しようとすると\n",
    "            raise ValueError('input shape inconsistency') # エラーを上げてプログラムを終了させる\n",
    "        self.mean = mean\n",
    "    \n",
    "    def set_cov(self, cov):\n",
    "        if cov.shape != (self.dim, self.dim):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        if np.linalg.eigvalsh(cov)[0] <= 0:\n",
    "            raise ValueError('covariance matrix must be positive semidefinite.')\n",
    "        self.cov = cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "\n",
    "1. `log_pdf` を完成させよ。\n",
    "    - 入力は `sample_size` x `dim` の array\n",
    "    - 出力は長さ `sample_size` の array\n",
    "        - 各データの確率密度の対数を計算したい\n",
    "1. `fit` を完成させよ。\n",
    "    - 入力は `sample_size` x `dim` の array\n",
    "    - `self.mean` と `self.cov` を最尤推定で更新する\n",
    "1. `sample` を完成させよ。\n",
    "    - 入力は `sample_size`\n",
    "    - 出力は平均 `self.mean`、分散`self.cov` の正規分布に従う乱数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# だいたいの手順\n",
    "\n",
    "- とりあえず中で実行すべき数式を書き下す\n",
    "    - `log_pdf` だと、 $\\log p(x \\mid \\mu, \\Sigma)$ を計算することになるので、実装できるくらいの粒度でその式を書いてみる\n",
    "    - `fit` だと、最尤推定量を計算することになるので、最尤推定量の計算式を導出する\n",
    "- `numpy` などで実装するには何が必要かを考える＆対応する機能が存在するか検索する\n",
    "    - `log_pdf` の場合は行列式や逆行列を計算する必要があるかも？\n",
    "- 実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Gaussian:\n",
    "    def __init__(self, dim):\n",
    "        '''コンストラクタ（みたいなもの）\n",
    "        オブジェクトを作るときに初めに実行される。\n",
    "        内部状態の初期化に使う\n",
    "        '''\n",
    "        self.dim = dim\n",
    "        '''\n",
    "        self = オブジェクトを指す。 self.dim は、オブジェクトの dim という変数を指す。\n",
    "        上の命令は、 self.dim に dim の値を代入することを表す\n",
    "        '''\n",
    "        self.set_mean(np.random.randn(dim)) # オブジェクトの mean という変数をランダムに初期化\n",
    "        self.set_cov(np.identity(dim))\n",
    "        \n",
    "    def log_pdf(self, X):\n",
    "        ''' 確率密度関数の対数を返す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        log_pdf : array, shape (sample_size,)\n",
    "        '''\n",
    "        if X.shape[1] != self.dim: # 入力の形をチェックしています\n",
    "            raise ValueError('X.shape must be (sample_size, dim)')\n",
    "        return -0.5 * np.sum((X - self.mean) * (np.linalg.solve(self.cov, (X - self.mean).T).T), axis=1) \\\n",
    "            -0.5 * self.dim * np.log(2.0 * np.pi) - 0.5 * np.linalg.slogdet(self.cov)[1]\n",
    "\n",
    "    def fit(self, X):\n",
    "        ''' X を使って最尤推定をする\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        '''\n",
    "        if X.shape[1] != self.dim: # 入力の形をチェックしています\n",
    "            raise ValueError('X.shape must be (sample_size, dim)')\n",
    "        self.set_mean(X.mean(axis=0))\n",
    "        self.set_cov((X - self.mean).T @ (X - self.mean) / X.shape[0])\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        ''' 現状のパラメタを使って `sample_size` のサイズのサンプルを生成する\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        sample_size : int\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "            各行は平均 `self.mean`, 分散 `self.cov` の正規分布に従う\n",
    "        '''\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, size=sample_size)\n",
    "        \n",
    "    def set_mean(self, mean):\n",
    "        if mean.shape != (self.dim,):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        self.mean = mean\n",
    "    \n",
    "    def set_cov(self, cov):\n",
    "        if cov.shape != (self.dim, self.dim):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        if np.linalg.eigvalsh(cov)[0] <= 0:\n",
    "            raise ValueError('covariance matrix must be positive semidefinite.')\n",
    "        self.cov = cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ポイント\n",
    "\n",
    "1. 逆行列を使わず、線型方程式を解く\n",
    "1. for文を使わず、行列演算で頑張る\n",
    "$$ \\sum_{n=1}^N x_n x_n^\\top = \\begin{bmatrix}x_1 & x_2 & \\dots & x_N\\end{bmatrix} \\begin{bmatrix}x_1^\\top \\\\ x_2^\\top \\\\ \\vdots \\\\ x_N^\\top\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように分解してみるとわかる\n",
    "$$\n",
    " \\begin{bmatrix}x_1 & x_2 & \\dots & x_N\\end{bmatrix} = \\begin{bmatrix}x_1 & 0 & \\dots & 0\\end{bmatrix} + \\begin{bmatrix}0 & x_2 & \\dots & 0\\end{bmatrix} + \\cdots + \\begin{bmatrix}0 & 0 & \\dots & x_N\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスの使い方\n",
    "\n",
    "- オブジェクトを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Gaussian(2) # my_model というオブジェクトが出来た"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_model.mean, my_model.cov) # 平均、共分散行列を持っている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_1 = Gaussian(2) # 他のオブジェクトも作れる\n",
    "print(my_model_1.mean, my_model_1.cov) # 平均はランダムに初期化されるため my_model とは異なる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 命令する（メソッドを実行する）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.multivariate_normal(np.array([1.0, 2.0]), np.array([[1.0, 0.9], [0.9, 4.0]]), size=100)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(X) # X で最尤推定をして、 mean, cov を更新する\n",
    "print(my_model.mean, my_model.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルサイズを大きくすると、真値に近くなる\n",
    "X = np.random.multivariate_normal(np.array([1.0, 2.0]), np.array([[1.0, 0.9], [0.9, 4.0]]), size=10000)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()\n",
    "my_model.fit(X)\n",
    "print(my_model.mean, my_model.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプリングを試してみる\n",
    "sample = my_model.sample(10000)\n",
    "plt.scatter(sample[:, 0], sample[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.mean = np.array([0, 0, 0]) # オブジェクトの変数に直接アクセスすることもできるが、おかしな値に設定してもエラーが出ない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.set_mean(np.array([0, 0, 0])) # メソッドの中で配列のサイズのチェックを行なっているため、ちゃんとエラーが出て止まる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.set_mean(np.array([0, 0]))\n",
    "my_model.set_cov(np.identity(2))\n",
    "np.exp(my_model.log_pdf(np.array([[0,0]]))) # 1次元の Normal distribution だと 0.4 くらいなので、二次元だと0.16くらいのはず"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "\n",
    "- 統計モデルはクラスを使って書く\n",
    "    - 内部状態 = モデルのパラメタ、ハイパーパラメタ\n",
    "    - メソッド = パラメタ推定、予測、入力チェック、内部状態更新\n",
    "- メソッドの入力や内部状態の更新時に、データの型チェックを行う\n",
    "    - バグの早期発見につながる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "\n",
    "1. さいころの目\n",
    "1. 前回作った PCA をクラスの形で書き換えよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice:\n",
    "    \n",
    "    def __init__(self, n_faces):\n",
    "        self.n_faces = n_faces\n",
    "        self.set_prob(np.ones(self.n_faces) / self.n_faces)\n",
    "        \n",
    "    def set_prob(self, prob_array):\n",
    "        if not np.allclose(prob_array.sum(), 1.0):\n",
    "            raise ValueError('prob_array must be normalized.')\n",
    "        if prob_array.shape != (self.n_faces,):\n",
    "            raise ValueError(f'prob_array must be of shape ({self.n_faces},)')\n",
    "        self.prob_array = prob_array\n",
    "        \n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_faces, )\n",
    "            X[i] は i 番目の目が出た回数を表す\n",
    "        '''\n",
    "        self.set_prob(X / X.sum())\n",
    "    \n",
    "    def sample(self, n_trials):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_trials : int\n",
    "            さいころを振る回数\n",
    "        \n",
    "        Returns\n",
    "        ------\n",
    "        X : array, shape (n_faces,)\n",
    "            X[i] は i 番目の目が出た回数を表す\n",
    "        '''\n",
    "        return np.random.multinomial(n_trials, self.prob_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eigh\n",
    "\n",
    "class PCA:\n",
    "    def __init__(self, input_dim, n_components):\n",
    "        self.input_dim = input_dim\n",
    "        self.n_components = n_components\n",
    "        self.set_encoder(np.eye(self.input_dim)[:self.n_components, :])\n",
    "    \n",
    "    def set_encoder(self, encoder):\n",
    "        if encoder.shape != (self.n_components, self.input_dim):\n",
    "            raise ValueError(f'encoder must have shape {(self.n_components, self.input_dim)}')\n",
    "        if np.abs(encoder @ encoder.transpose() - np.eye(self.n_components)).max() > 1e-4:\n",
    "            raise ValueError('encoder must be orthonormal.')\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def fit(self, X):\n",
    "        eig_val, eig_vec = eigh(X.T @ X)\n",
    "        self.set_encoder(eig_vec[:, -self.n_components:].transpose())\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X @ self.encoder.transpose()\n",
    "\n",
    "    def inverse_transform(self, z):\n",
    "        return z @ self.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# データを取得\n",
    "dataset = fetch_olivetti_faces()\n",
    "num_examples, row_size, col_size = dataset['images'].shape\n",
    "X = dataset['data']\n",
    "\n",
    "# 平均0にしておく（しなくてもまあ大丈夫だけど）\n",
    "X_mean = X.mean(axis=0)\n",
    "X_centered = X - X_mean\n",
    "\n",
    "n_components=20\n",
    "\n",
    "pca = PCA(X.shape[1], n_components)\n",
    "pca.fit(X_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pca.transform(X_centered)\n",
    "X_rec = pca.inverse_transform(z) + X_mean\n",
    "idx = 190\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dataset['images'][idx], cmap=plt.cm.gray) # 左が元の画像\n",
    "ax2.imshow(X_rec[idx].reshape(row_size, col_size), cmap=plt.cm.gray) # 右が再構成画像\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
