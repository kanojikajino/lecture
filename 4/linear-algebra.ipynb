{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 応用計量分析２（第4回）\n",
    "\n",
    "線形代数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 担当教員: 梶野 洸（かじの ひろし）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本日の目標\n",
    "\n",
    "- 線形代数を思い出す\n",
    "- Python で線形代数の数値計算をやる\n",
    "- 主成分分析（PCA）を実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形代数の登場人物\n",
    "\n",
    "- ベクトル $x = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$\n",
    "- 行列 $A = \\begin{bmatrix} 1 & 0\\\\ 0 & 1\\end{bmatrix}$\n",
    "- リストで書けばいい？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 0] # x をリストで書いてみた\n",
    "#print(x)\n",
    "A = [[1, 0], [0, 1]]\n",
    "#print(A)\n",
    "print(x + x) # x + x は、ベクトルでは [2, 0] になってほしいが..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトルどうしの足し算を関数として定義する必要がある\n",
    "def add_vectors(x, y):\n",
    "    z = []\n",
    "    for i in range(len(x)):\n",
    "        z.append(x[i] + y[i])\n",
    "    return z\n",
    "add_vectors(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形代数で使う計算\n",
    "\n",
    "色々あるので全部書くのはめんどくさい...\n",
    "\n",
    "- ベクトル/行列どうしの足し算引き算\n",
    "- 行列とベクトルの積、行列どうしの積\n",
    "- ノルム、内積などなど"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  `numpy` 使う\n",
    "\n",
    "- 基本的な線形代数の計算が実装されているライブラリ\n",
    "- リストではなく `numpy.ndarray` というオブジェクトでベクトルを定義する\n",
    "    - リストどうしの足し算だとリストの連結になってしまう\n",
    "    - `numpy.ndarray` どうしの足し算だとベクトルの足し算となる！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オブジェクト？ `numpy.ndarray`？\n",
    "\n",
    "- 全てのものはオブジェクトと呼ばれる\n",
    "    - `1`, `[1,0,3]`, `'hello world'` など\n",
    "- 数字, 文字列などは、オブジェクトの「型」と呼ばれる\n",
    "    - 例1. `1` の型は、数字\n",
    "        - `2` の型も数字なので、 `1` と `2` は同じ型\n",
    "    - 例2. `[1,0,3]` の型は、リスト\n",
    "    - `numpy.ndarray` も型\n",
    "    - オブジェクトの「種類」と理解できる\n",
    "    - `type` で型を調べられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/type_object.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type('1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type([1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- それぞれの型には特有の関数がある\n",
    "    - `<オブジェクト>.<関数名>(<引数>)` と書くのが基本\n",
    "    - 読み方: <オブジェクト> に、そのオブジェクトに対して定義されている <関数名> を適用する。その時の引数は <引数> で指定する\n",
    "    - 別の読み方: <オブジェクト> の中の <関数名> を実行する。その時の引数は <引数> で指定する\n",
    "    - `A.B` は、 `A` の中の `B` という意味合いで広く使われる\n",
    "        - `A` がオブジェクトではないこともあるし、 `B` が関数でないこともある\n",
    "    - 何か値が返ってくる場合もあるし、オブジェクトが変更されるだけで何も返ってこない場合もある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/type_func.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 0] # x にリストを入れる\n",
    "x.append(3) # リストには `append` という関数が用意されている。引数のオブジェクトを末尾に付け足す機能\n",
    "# x というオブジェクトに対して、 `append` という関数を適用する。その時に引数として 3 を取る\n",
    "y = [1, 1, 'hello']\n",
    "y.append(3)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 0]\n",
    "print(x + x) # 足し算も、リスト用に特別に用意されている\n",
    "print(x.__add__(x)) # 上の書き方っぽくするとこう書ける\n",
    "# x というオブジェクトに対して、 `__add__` という関数を適用する。その時に引数として x を取る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまで踏まえた上で `numpy` を使ってみる\n",
    "\n",
    "- `numpy.ndarray` 型のオブジェクトを作りたい\n",
    "    - まず `numpy` を使えるようにしないといけない\n",
    "        - 標準ライブラリでないのでそのままでは使えないことがある\n",
    "        - 今回はインストールは不要（ repl.it に入っている）\n",
    "    - `numpy.array(<リスト>)` を実行すると <リスト> を `numpy.ndarray` に変換したものが返ってくる\n",
    "        - `numpy` の中の `array` という関数を実行している\n",
    "        - `numpy` はライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy # numpy というライブラリを使うという宣言\n",
    "x = numpy.array([1, 0]) # numpy.array という関数を使う。リストを入力するとベクトルを出力する（ベクトルは色々線形計算が定義されている）\n",
    "print(x)\n",
    "print(type(x))\n",
    "print(type([1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy を使いたいけど、 numpy という名前だと長いので np という短い名前で呼びたい\n",
    "x = np.array([1, 0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベクトル\n",
    "$x=\\begin{bmatrix}1 \\\\ 0 \\end{bmatrix}$, $y=\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$ とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([1.0, 0])\n",
    "y = np.array([0, 1.0])\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベクトルのスカラー倍: $3x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 0.0])\n",
    "print(3.0 * x) # 実数との掛け算も自然に定義されている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベクトル同士の足し算・引き算: $x + y$, $x - y$\n",
    "- より一般的に線形結合: $3x - 10y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 0])\n",
    "y = np.array([0, 1.0])\n",
    "# ベクトル演算が自然に定義されている\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(3 * x - 10 * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 内積: $x \\cdot y, (3x - y) \\cdot (x+2y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 0.0])\n",
    "y = np.array([0, 1.0])\n",
    "print(x @ y)\n",
    "print((3 * x - y) @ (x + 2 * y))\n",
    "print(np.dot(x, y)) # 関数の形で書くこともできる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※内積は、2つベクトルを受け取って、1つのスカラーを返す**関数**としても書ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノルム: $\\|2x - y\\|_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 0.0])\n",
    "y = np.array([0, 1.0])\n",
    "print(((2 * x - y) @ (2 * x - y)) ** (0.5)) # 内積を使って計算した場合\n",
    "print(np.linalg.norm(2 * x - y)) # numpyの関数を使って計算した場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 要素積（アダマール積）: $x\\circ y$\n",
    "\n",
    "各次元で積を取る演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 0.0])\n",
    "y = np.array([0, 1.0])\n",
    "print(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 2, 3, 4])\n",
    "print(x[1]) # 1 番目の要素\n",
    "print(x[0:2]) # 0 から2番目の要素（2番目は含まない）\n",
    "print(x[-1]) # 一番最後の要素\n",
    "print(x[-3:-1]) # 最後から3番目〜1番目の要素（-1番目を含まない）\n",
    "print(x[-3:]) # 最後から3番目〜最後の要素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "- ベクトルはnumpyの `ndarray` というオブジェクトで定義する\n",
    "- 普通の数値と同じような演算ができる\n",
    "- 内積やノルムなど、線形代数特有の計算の関数もある\n",
    "    - 内積: `np.dot`, `@`\n",
    "    - ノルム: `np.linalg.norm`\n",
    "    - アダマール積: `*`\n",
    "- 構成要素の取り出し方は色々ある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 想定QA\n",
    "\n",
    "Q. 欲しい関数があるかどうか調べたい\n",
    "\n",
    "A. ググるかライブラリのAPIを見る（numpyは[ここ](https://docs.scipy.org/doc/numpy/reference/)）\n",
    "- \"numpy <ほしい機能>\" みたいにググる\n",
    "    - \"numpy 内積\" とか \"numpy inner product\" とか\n",
    "    - 基本的には公式ドキュメントがもっとも正しいはず\n",
    "    - プログラミングには英語は必須"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. `np.dot` とか `np.linalg.norm` とかなんやねん\n",
    "\n",
    "A. ライブラリは階層構造になっている。\n",
    "- `np.dot` は、`numpy` (`np`と書いてる)直下に定義された `dot` という関数、\n",
    "- `np.linalg.norm` は、`numpy` の下の `linalg` (linear algebra; 線形代数)という線形代数の関数をまとめた集まりのなかの `norm` という関数\n",
    "と解釈する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習4.1\n",
    "\n",
    "1. `input_list` を入力とし、それを `numpy.ndarray` に変換して出力する関数 `list2ndarray` を実装せよ\n",
    "   - `input_list` はリスト型のオブジェクトで、各要素は `int` または `float` 型と仮定する\n",
    "1. `x_array`, `y_array` という二つの `numpy.ndarray` を入力とし、 `x_array` と `y_array` の差のl2ノルムを出力する関数 `dist` を実装せよ\n",
    "   - `x_array`, `y_array` は `numpy.ndarray` 型のオブジェクトで、同じ系列長であると仮定する\n",
    "1. `x_array` を入力とし、その一番はじめの要素と最後の要素を取り除いた `numpy.ndarray` を出力する関数 `extract` を実装せよ\n",
    "   - `x_array` は `numpy.ndarray` 型のオブジェクトで系列長は3以上だと仮定する\n",
    "1. `x_array` と `idx` を入力とし、`x_array` の `idx` 番目の要素を 0 に書き換える関数 `drop` を実装せよ\n",
    "   - `x_array` は `numpy.ndarray` 型のオブジェクトであると仮定し、 `x_array` の系列長を L とする\n",
    "   - `idx` は `int` 型のオブジェクトでかつ 0 以上 L - 1 以下の値をとると仮定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列\n",
    "$A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 2 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array にリストのリストを渡すと行列\n",
    "A = np.array([[1.0, 1.0], \n",
    "                      [0.0, 2.0]])\n",
    "print(A)\n",
    "type(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列とベクトルの積\n",
    "$Ax$\n",
    "\n",
    "$x^\\top A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 0])\n",
    "print(A @ x)\n",
    "print(x @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A @ np.array([1,2,3,4])) # 2x2の行列に4次元のベクトルは掛けられない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列と行列の積\n",
    "$A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 2 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 & 1 \\\\ 1 & 2 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.0, 1.0],\n",
    "              [0.0, 2.0]])\n",
    "B = np.array([[0.0, 1.0],\n",
    "              [1.0, 2.0]])\n",
    "print(A @ B)\n",
    "print(B @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形方程式\n",
    "\n",
    "$A\\in\\mathbb{R}^{N\\times N}$, $b\\in\\mathbb{R}^N$ としたとき、\n",
    "$Ax=b$ を満たす $x\\in\\mathbb{R}^N$ を求める。\n",
    "\n",
    "$A$ が正則行列（＝逆行列を持つ）のとき、 $x = A^{-1}b$ が解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二通りの実装方法がある\n",
    "- 逆行列を求めるアルゴリズム(Gauss-Jordanなど)を利用\n",
    "- 直接線形方程式を解くアルゴリズム(LU分解)を利用\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "！！なるべく直接線形方程式を解くアルゴリズムを利用すべき！！\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LU 分解の方がそもそも速い\n",
    "    - $A$ の形によっては更に速くなる\n",
    "- `numpy` では逆行列を求めるのに$AX=I$を解いている（＝線形方程式を解くのと同じ計算時間がここで必要）\n",
    "    - さらに $A^{-1}b$ を計算しないといけないので計算時間的に損\n",
    "\n",
    "（参考）伊理正夫, 藤野和建: 数値計算の常識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習4.2\n",
    "\n",
    "1. $D\\times D$ 正則行列 $A$ と $D$ 次元ベクトル $x$ を入力として、$\\sqrt{x^\\top A^{-1}x}$ を出力する関数 `quadratic` を完成させよ。ただし $A$, $x$ 共に numpy.array として与えられるとする。\n",
    "1. $D\\times D$ 対称行列 $A$ を入力として、$A$ の第二固有値（固有値の中で二番目に大きいもの）を出力する関数 `second_eig` を完成させよ。\n",
    "1. $D\\times D$ 行列 $A$、$D$ 次元ベクトル $x$ 、自然数 $k$ を入力として、\n",
    "\n",
    "$\n",
    "\\begin{array}\n",
    "\\nonumber v_1 &= \\dfrac{A^k x}{\\|A^k x\\|}\\\\\n",
    "\\lambda_1 &= v_1^\\top A v_1\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "で定義される$\\lambda_1$を出力する関数 `power_iter` を完成させよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解説: べき乗法\n",
    "\n",
    "- $A\\in\\mathbb{R}^{N\\times N}$ の固有値と対応する固有ベクトルを $\\lambda_1,\\dots,\\lambda_N$, $v_1,\\dots,v_N$ とする。\n",
    "- $|\\lambda_1| > |\\lambda_2| > \\cdots > |\\lambda_N|$ とする。\n",
    "\n",
    "任意のベクトル $x\\in\\mathbb{R}^N$ は、固有ベクトルで展開できる（固有ベクトルは基底を成す）:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "x = \\sum_{n=1}^{N}c_n v_n\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ を掛け続けると絶対値最大の固有値に対応する固有ベクトルが（相対的に）強調される:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "A^k x &= \\sum_{n=1}^{N}c_n A^k v_n = \\sum_{n=1}^N c_n \\lambda_n^k v_n\\\\\n",
    "&= \\lambda_1^k \\sum_{n=1}^N c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^k v_n\\\\\n",
    "&\\approx \\lambda_1^k c_1 v_1\n",
    "\\end{eqnarray}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 適当なベクトルに行列 $A$ を掛け続けると $v_1$ が求まる\n",
    "- $\\lambda_1 = \\dfrac{v_1^\\top A v_1}{v_1^\\top v_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2, 1], [1, 2]])\n",
    "x = np.array([1, 2])\n",
    "for i in range(100):\n",
    "    x = A @ x\n",
    "    x = x / np.linalg.norm(x) # ベクトルを正規化しないと発散する\n",
    "print(x@A@x / (x@x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "\n",
    "- ベクトル、行列は `numpy` を使う\n",
    "- 固有値・固有ベクトルなどの計算もできる\n",
    "- 線形方程式も解ける\n",
    "- 逆行列を求める必要があるか考える（線形方程式を解けばいい場合は線形方程式を解く）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析, PCA\n",
    "\n",
    "データ $x_1,\\dots,x_N\\in \\mathbb{R}^D$ があったとき、その\"特性\"を保ったまま低次元表現を得たい。\n",
    "- データを目で見たい（100次元だと見られないけど2次元なら）\n",
    "- 同じ情報量ならば低次元の方が学習しやすい\n",
    "- 特性の定義によって様々な手法がある\n",
    "- $K~(<D)$次元表現を得る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析（1次元の場合）\n",
    "\n",
    "Q. データを1次元に射影するとき、どのように射影すれば一番データの特性を保存できるか？\n",
    "\n",
    "A. データの分散が最も大きくなる軸に射影すれば良さそう\n",
    "<img src=\"figs/pca_variance.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析（1次元の場合）の定式化\n",
    "\n",
    "- $X = \\begin{bmatrix} x_1 & x_2 & \\dots & x_N \\end{bmatrix}^\\top$\n",
    "    - データの平均を $\\bar{x}=\\frac{1}{N}\\sum_{n=1}^N x_n$ とする\n",
    "- $u_1\\in\\mathbb{R}^D$ で定められる軸に射影することを考える\n",
    "    - $u_1^\\top u_1=1$ とする\n",
    "- $u_1$ で定められる軸上での $x_n$ の座標は $u_1^\\top x_n$\n",
    "- $u_1$ で定められる軸上での $X$ の分散は $\\frac{1}{N}\\sum_{n=1}^N (u_1^\\top x_n - u_1^\\top \\bar{x})^2$\n",
    "<img src=\"figs/pca_projection.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析（1次元の場合）の定式化\n",
    "\n",
    "分散が最大になる方向が知りたいので、以下の最適化問題を解く\n",
    "$$\n",
    "\\mathrm{maximize}_{u_1\\in\\mathbb{R}^D} \\frac{1}{N}\\sum_{n=1}^N (u_1^\\top x_n - u_1^\\top \\bar{x})^2\\\\\n",
    "\\mathrm{subject\\ to}\\ u_1^\\top u_1=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析（1次元の場合）の解法\n",
    "\n",
    "まず目的関数を書き換える\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{1}{N}\\sum_{n=1}^N (u_1^\\top x_n - u_1^\\top \\bar{x})^2 &= \\frac{1}{N}\\sum_{n=1}^N u_1^\\top(x_n - \\bar{x}) (x_n - \\bar{x})^\\top u_1\\\\\n",
    "&=u_1^\\top \\Sigma u_1\n",
    "\\end{align}\n",
    "where $\\Sigma = \\frac{1}{N} \\sum_{n=1}^N (x_n - \\bar{x}) (x_n - \\bar{x})^\\top$.\n",
    "\n",
    "すると最適化問題は以下のように書き換わる\n",
    "\n",
    "$$\n",
    "\\mathrm{maximize}_{u_1\\in\\mathbb{R}^D} u_1^\\top \\Sigma u_1\\\\\n",
    "\\mathrm{subject\\ to}\\ u_1^\\top u_1=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析（1次元の場合）の解法\n",
    "ラグランジュ未定乗数法を使う。ラグランジアンは\n",
    "\\begin{align}\n",
    "\\mathcal{L}(u_1; \\lambda_1) = u_1^\\top \\Sigma u_1 + \\lambda_1 (1 - u_1^\\top u_1)\n",
    "\\end{align}\n",
    "\n",
    "最適解 $u_1^\\star$ で停留点になっていることが必要なので、\n",
    "\\begin{align}\n",
    "\\dfrac{\\partial}{\\partial u_1} \\mathcal{L}(u_1^\\star; \\lambda_1) = \\Sigma u_1^\\star - \\lambda_1 u_1^\\star = 0\n",
    "\\end{align}\n",
    "つまり $\\lambda_1$ は $\\Sigma$ の固有値で $u_1^\\star$ はそれに対応する（単位）固有ベクトルであることが必要。また目的関数は\n",
    "\\begin{align}\n",
    "u_1^\\top \\Sigma u_1 = \\lambda_1\n",
    "\\end{align}\n",
    "となるため、$\\lambda_1$ は $\\Sigma$ の最大固有値で、$u_1^\\star$ は最大固有値に対応する長さ1の固有ベクトルである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析（2次元以上）について\n",
    "\n",
    "- 第一主成分は分散共分散行列 $\\Sigma$ の最大固有値に対応する固有ベクトルだった。\n",
    "- Q. データを $K (\\geq 2)$ 次元に落としたい場合はどうすればいいのか？\n",
    "- A. $K$ 次元空間に落とした時の分散を考えれば良さそう\n",
    "    - $\\Sigma$ の固有値の大きい方から $K$ 個とってきて、対応する固有ベクトルも持ってくる: $\\{(\\lambda_k, u_k)\\}_{k=1}^K$\n",
    "    - $U=\\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top \\in\\mathbb{R}^{K\\times D}$ として、 $U$ で $K$ 次元空間に射影したらいい\n",
    "    - 証明略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの再構成\n",
    "- $D$次元ベクトル $x$ を $K$ 次元ベクトル $z$ に変換した\n",
    "- $z$ から $x$ に戻せる？→情報は落ちるけどできなくはない\n",
    "<img src=\"figs/decode.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アルゴリズム\n",
    "\n",
    "- 入力: $x_1,\\dots, x_N\\in\\mathbb{R}^D$, $K\\in\\mathbb{N}$\n",
    "- 出力: $z_1,\\dots, z_N\\in\\mathbb{R}^K$\n",
    "\n",
    "\n",
    "1. $\\bar{x}=\\frac{1}{N}\\sum_{n=1}^N x_n$\n",
    "1. $\\Sigma=\\frac{1}{N}\\sum_{n=1}^N (x_n-\\bar{x}) (x_n-\\bar{x})^\\top$\n",
    "1. $\\Sigma$ の固有値と対応する固有ベクトル $(\\lambda_1, u_1),\\dots,(\\lambda_D, u_D)$ を求める（$\\lambda_1\\geq\\cdots\\geq \\lambda_D$）\n",
    "    - ただし $\\|u_d\\|=1$ for all $d=1,\\dots,D$.\n",
    "1. $U=\\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top$ として、$z_n=Ux_n$ を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "\n",
    "- PCA は分散共分散行列を固有値分解すればできる\n",
    "- 固有値（＋固有ベクトルも）の大きい方から順番にとってくればいい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習4.3\n",
    "\n",
    "1.  $X=\\begin{bmatrix}x_1 & x_2 &\\dots & x_N\\end{bmatrix}^\\top$ を入力として、$\\Sigma = \\frac{1}{N} \\sum_{n=1}^N (x_n - \\mu) (x_n - \\mu)^\\top$ を出力する関数 `covariance` を完成させよ。ただし $\\mu=\\frac{1}{N}\\sum_{n=1}^N x_n$ とし、入出力形式は以下の通りとする。\n",
    "    - 入力: N x D の `numpy.ndarray` （N: サンプルサイズ、D: 次元）\n",
    "    - 出力: D x D の `numpy.ndarray`\n",
    "\n",
    "1. 対称行列 A を入力とし、その固有値からなる `numpy.ndarray` と対応する固有ベクトルからなる `numpy.ndarray` を返す関数 `eig` を完成させよ。ただし入出力は以下の通りとする。\n",
    "   - 入力: D x D の `numpy.ndarray`\n",
    "   - 出力:\n",
    "     - `eig_val_array`: 長さD の `numpy.ndarray` で、 A の固有値が昇順に並んでいる（小さい固有値がはじめ、大きい固有値が後ろ）。\n",
    "     - `eig_vec_array`: D x D の `numpy.ndarray` で、A の固有ベクトルからなる。 `eig_vec_array[:, i]` は `eig_val_array[i]` に対応する長さ1の固有ベクトル。\n",
    "\n",
    "1. PCA を実行する関数を完成させよ\n",
    "   - 入力\n",
    "     - `X`: N x D の `numpy.ndarray` （N: サンプルサイズ、D: 次元）\n",
    "     - `K`: 1 以上D以下の `int`\n",
    "   - 出力\n",
    "     - `Z`: N x K の `numpy.ndarray` （`Z[n, :]`は、PCAを用いて`X[n, :]`をK次元に落としたもの）\n",
    "     - `U`: K x D の `numpy.ndarray` （PCAで次元圧縮するときに用いる、D次元ベクトルをK次元ベクトルに変換する行列）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA の実装\n",
    "\n",
    "- PCA でデータを2次元で見てみる\n",
    "- 主成分を見てみる\n",
    "- 再構成してみる\n",
    "\n",
    "→ 見て楽しいので画像データを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# データを取得\n",
    "dataset = fetch_olivetti_faces()\n",
    "num_examples, row_size, col_size = dataset['images'].shape\n",
    "X = dataset['data']\n",
    "\n",
    "# 平均0にしておく\n",
    "X_mean = X.mean(axis=0)\n",
    "X_centered = X - X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顔データを表示してみる\n",
    "plt.imshow(dataset['images'][0], cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "X_centered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/img2vec.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習4.3の解答的なもの\n",
    "\n",
    "上で定義した `X_centered` に対してPCAのアルゴリズムを適用した時に得られる低次元表現 $Z\\in\\mathbb{R}^{N\\times K}$ と変換に用いる行列 $U\\in\\mathbb{R}^{K\\times D}$ を求めるプログラムを書く\n",
    "\n",
    "\n",
    "1. $\\Sigma=\\sum_{n=1}^N x_n x_n^\\top$ を計算せよ（$x_n$ の平均は0に変換済み）\n",
    "1. $\\Sigma$ の固有値と対応する固有ベクトル $(\\lambda_1, u_1),\\dots,(\\lambda_D, u_D)$ を計算せよ（$\\lambda_1\\geq\\cdots\\geq \\lambda_D$）\n",
    "    - ヒント: 対称行列の固有値分解を行う関数 https://numpy.org/doc/stable/reference/generated/numpy.linalg.eigh.html\n",
    "1. $U=\\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top$ として、$z_n=Ux_n$ を計算せよ\n",
    "    - 例えば $K=20$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\Sigma=\\sum_{n=1}^N x_n x_n^\\top$ を計算せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = X_centered.shape[0]\n",
    "dim = X_centered.shape[1]\n",
    "\n",
    "# 定義通り地道に sigma を作ってもいい\n",
    "sigma = np.zeros((dim, dim))\n",
    "for each_example in range(sample_size):\n",
    "    sigma = sigma + np.outer(X_centered[each_example], X_centered[each_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X = \\begin{bmatrix}x_1 \\dots, x_N\\end{bmatrix}^\\top$ としたとき、\n",
    "\n",
    "$$\n",
    "X^\\top X = \\sum_{n=1}^N x_n x_n^\\top\n",
    "$$\n",
    "\n",
    "という関係を使ってもいい（こっちの方が圧倒的に速い）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma には上で計算したものが入っている\n",
    "print(np.linalg.norm(sigma - X_centered.T @ X_centered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $A$ の固有値と対応する固有ベクトル $(\\lambda_1, u_1),\\dots,(\\lambda_D, u_D)$ を計算せよ（$\\lambda_1\\geq\\cdots\\geq \\lambda_D$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eigh\n",
    "eig_val, eig_vec = eigh(sigma)\n",
    "print(eig_val)\n",
    "print(eig_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. $U=\\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top$ として、$z_n=Ux_n$ を計算せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "U = eig_vec[:, -K:].T\n",
    "print(U.shape)\n",
    "z = (U @ X.T).T\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "PCA を実行する関数を書け\n",
    "\n",
    "- 入力: データ $X\\in\\mathbb{R}^{N\\times D}$, 次元 $K$\n",
    "- 出力: 変換されたデータ $Z\\in\\mathbb{R}^{N\\times K}$, 変換にもちいる線形変換 $U\\in\\mathbb{R}^{K\\times D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eigh\n",
    "def pca(X, K):\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    sigma = X.T @ X\n",
    "    eig_val, eig_vec = eigh(sigma)\n",
    "    U = eig_vec[:, -K:].T\n",
    "    z = (U @ X.T).T\n",
    "    return z, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca を実行\n",
    "K=20\n",
    "z, U = pca(X_centered, K)\n",
    "print(z.shape, U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V の行ベクトルが正規直交基底であることを確認\n",
    "print('distance from the identity:', np.abs(U @ U.T - np.identity(K)).max())\n",
    "print('mean reconstruction loss: ',((X_centered - (U.T @ z.T).T) * (X_centered - (U.T @ z.T).T)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの貼る空間の固有ベクトルを見てみる\n",
    "plt.imshow(-U[-1].reshape(row_size, col_size), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この場合は2次元に落としてもよくわからない...\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "K = 2\n",
    "z, U = pca(X_centered, K)\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, 10))\n",
    "for each_idx in range(100):\n",
    "    plt.scatter(z[each_idx, 0], z[each_idx, 1], color=colors[dataset['target'][each_idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構成 (K=2)\n",
    "K = 2\n",
    "z, U = pca(X_centered, K)\n",
    "X_rec = (U.T @ z.T).T + X_mean\n",
    "idx = 190\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dataset['images'][idx], cmap=plt.cm.gray) # 左が元の画像\n",
    "ax2.imshow(X_rec[idx].reshape(row_size, col_size), cmap=plt.cm.gray) # 右が再構成画像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構成 (K=20)\n",
    "K = 20\n",
    "z, U = pca(X_centered, K)\n",
    "X_rec = (U.T @ z.T).T + X_mean\n",
    "idx = 190\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dataset['images'][idx], cmap=plt.cm.gray) # 左が元の画像\n",
    "ax2.imshow(X_rec[idx].reshape(row_size, col_size), cmap=plt.cm.gray) # 右が再構成画像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構成 (K=50)\n",
    "K = 50\n",
    "z, U = pca(X_centered, K)\n",
    "X_rec = (U.T @ z.T).T + X_mean\n",
    "idx = 190\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dataset['images'][idx], cmap=plt.cm.gray) # 左が元の画像\n",
    "ax2.imshow(X_rec[idx].reshape(row_size, col_size), cmap=plt.cm.gray) # 右が再構成画像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構成 (K=200)\n",
    "K = 200\n",
    "z, U = pca(X_centered, K)\n",
    "X_rec = (U.T @ z.T).T + X_mean\n",
    "idx = 190\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dataset['images'][idx], cmap=plt.cm.gray) # 左が元の画像\n",
    "ax2.imshow(X_rec[idx].reshape(row_size, col_size), cmap=plt.cm.gray) # 右が再構成画像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "\n",
    "- 行列、ベクトルは `numpy` を使って実装する\n",
    "- 線形代数の操作は `numpy` の API を探せば実装されていることが多い\n",
    "- 主成分分析(principle component analysis; PCA) を実装した\n",
    "    - データを低次元空間に射影するアルゴリズム\n",
    "    - 低次元空間での分散を最小化する\n",
    "    - 固有値分解に帰着される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下、2020年の講義では用いない資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA をオートエンコーダとして導出する\n",
    "\n",
    "- 分散最大化として定式化されることが多いが、なぜ分散最大化したいのかがわからない人もいるかもしれない？\n",
    "- 他の説明を試みることでより納得できるようにしたい\n",
    "- 以下説明したいこと\n",
    "    - オートエンコーダとは？\n",
    "    - PCA のオートエンコーダ的な解釈は？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オートエンコーダ\n",
    "\n",
    "- 入力: データ $x_1,\\dots,x_N\\in\\mathbb{R}^D$\n",
    "- 出力: エンコーダ $\\mathrm{Enc}\\colon \\mathbb{R}^D\\rightarrow\\mathbb{R}^K$ とデコーダ $\\mathrm{Dec}\\colon \\mathbb{R}^K\\rightarrow\\mathbb{R}^D$ で、 $\\mathrm{Dec}(\\mathrm{Enc}(x_n))\\approx x_n$ ($n=1,\\dots,N$) となるもの\n",
    "    - 元に戻せるならばいいエンコーダ、デコーダっぽい気がする\n",
    "    - エンコーダを使うとデータ$x\\in\\mathbb{R}^D$の低次元表現$z\\in\\mathbb{R}^K$が得られる\n",
    "    - $\\mathrm{Enc}$, $\\mathrm{Dec}$ をニューラルネットワークで作るのが流行りの技術\n",
    "\n",
    "<img src=\"figs/autoencoder.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA は、$\\mathrm{Enc}$, $\\mathrm{Dec}$ を線形変換でモデル化したもの\n",
    "\n",
    "- エンコーダ $W\\in\\mathbb{R}^{K\\times D}$ は $\\mathbb{R}^D\\rightarrow\\mathbb{R}^K$ という関数としてみることもできる\n",
    "- $U\\in\\mathbb{R}^{K\\times D}$ を用いて定めるデコーダ $U^\\top$ は $\\mathbb{R}^K\\rightarrow\\mathbb{R}^D$ という関数としてみることもできる\n",
    "    - エンコード: $z = Wx$ \n",
    "    - デコード: $\\hat{x} = U^\\top z = U^\\top W x$\n",
    "    - $\\hat{x}\\approx x$ となってほしい\n",
    "    \n",
    "<img src=\"figs/pca.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定式化\n",
    "- $X = \\begin{bmatrix} x_1 & x_2 & \\dots & x_N \\end{bmatrix}^\\top$\n",
    "- 平均$0$であるとする: $\\sum_{n=1}^N x_n = 0$\n",
    "- 以下を満たす $W, U$ を求める\n",
    "\n",
    "$$\n",
    "\\min_{W, U\\in\\mathbb{R}^{K\\times D}} \\sum_{n=1}^{N}\\|x_n - U^{\\top}Wx_n\\|_{2}^2 \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからの流れ\n",
    "\n",
    "**補題1** エンコーダ、デコーダをモデル化するのに $W$, $U$ の二つのパラメタを用意していたが、実は $V\\in\\mathbb{R}^{K\\times D}$ such that $VV^\\top=I$ となるパラメタ一つで十分（エンコーダが $V$, デコーダが $V^\\top$）\n",
    "\n",
    "**補題2** 目的関数はトレースを用いて綺麗にかける\n",
    "\n",
    "**補題3** 最大化したい目的関数の上界を求めることができる\n",
    "\n",
    "**定理** 固有値・固有ベクトルを用いて解を構成すると目的関数の上界を達成できる。これは最適解（の一つ）が求まったことを示している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補題1\n",
    "\n",
    "式(1)の最適値は\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{V\\in\\mathbb{R}^{K\\times D},\\ VV^\\top=I} \\sum_{n=1}^{N}\\|x_n - V^{\\top}Vx_n\\|_{2}^2\\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "の最適値と等しい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 証明\n",
    "- $R = \\{U^\\top W x \\mid x \\in \\mathbb{R}^D\\}$ とすると、$R$は$\\mathbb{R}^D$中の$K$次元線型部分空間\n",
    "- $R$ の正規直交基底を$V=\\begin{bmatrix}v_1 & \\dots & v_K\\end{bmatrix}^\\top\\in\\mathbb{R}^{D\\times K}$とする。\n",
    "- $V^\\top Vx = \\arg\\min_{\\tilde{x}\\in R} \\|x - \\tilde{x}\\|$が成り立つ。\n",
    "    - $R$ の元は $y\\in\\mathbb{R}^K$ を用いて $V^\\top y$ と書けることを利用して示す（演習）\n",
    "- 式(1)の最適解 $U^\\star$, $W^\\star$ と、それに対応する $R^\\star$, $V^\\star$ を持ってくると、\n",
    "$$\n",
    "\\begin{align}\n",
    "\\|x_n - {U^\\star}^\\top W^\\star x_n\\|^2 \\geq \\min_{\\tilde{x}_n\\in R^\\star}\\|x_n - \\tilde{x}_n\\|^2 = \\|x_n - {V^\\star}^\\top V^\\star x_n\\|^2\n",
    "\\end{align}\n",
    "$$\n",
    "    - 一つめの不等式は、${U^\\star}^\\top W^\\star x_n \\in R^\\star$ だから成立\n",
    "    - 二つめの不等式は、上の議論より成立\n",
    "- 上の不等式は、 $V^\\star$ は、最適解 $U^\\star, W^\\star$ と等しいかより小さい目的関数値を達成する、と言っている\n",
    "- より小さい目的関数値を達成することはあり得ないので、上の不等式は等号成立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補題2\n",
    "最適化問題(2)は\n",
    "$$\n",
    "\\max_{V\\in\\mathbb{R}^{K\\times D}, VV^\\top=I}\\mathrm{tr}\\left(V \\left(\\sum_{n=1}^N x_n x_n^\\top\\right)V^\\top\\right) \\tag{3}\n",
    "$$\n",
    "と同値。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明\n",
    "\n",
    "展開すれば良い。\n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^N \\|x_n - V^\\top V x_n\\|^2 = \\sum_{n=1}^N \\|x_n\\|^2 - 2\\sum_{n=1}^N x_n^\\top V^\\top V X_n + \\sum_{n=1}^N x_n^\\top V^\\top V V^\\top V x_n\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\sum_{n=1}^N \\|x_n\\|^2 - \\sum_{n=1}^N x_n^\\top V^\\top V x_n\n",
    "$$\n",
    "\n",
    "第二項は、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N x_n^\\top V^\\top V x_n = \\sum_{n=1}^N \\mathrm{tr}(x_n^\\top V^\\top V x_n)\n",
    "=  \\sum_{n=1}^N \\mathrm{tr}(x_n x_n^\\top V^\\top V) \\\\\n",
    "= \\mathrm{tr}\\left(\\left(\\sum_{n=1}^N x_n x_n^\\top\\right) V^\\top V\\right)\n",
    "= \\mathrm{tr}\\left(V\\left(\\sum_{n=1}^N x_n x_n^\\top\\right) V^\\top\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補題3\n",
    "$A=\\sum_{n=1}^N x_n x_n^\\top$ として、その固有値、固有ベクトルを $\\lambda_1,\\dots, \\lambda_D$, $u_1,\\dots,u_D$ とする（$\\lambda_1\\geq\\lambda_2\\geq\\cdots\\geq\\lambda_D$）。\n",
    "この時任意の $V\\in\\mathbb{R}^{K\\times D}, VV^\\top=I$ について\n",
    "\n",
    "$$\n",
    "\\mathrm{tr}\\left(V A V^\\top\\right) \\leq \\max_{w\\in[0,1]^D, \\sum_{d=1}^D w_d\\leq K}\\sum_{d=1}^D \\lambda_d w_d = \\sum_{d=1}^K \\lambda_d\n",
    "$$\n",
    "\n",
    "が成立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明\n",
    "$A=U^\\top \\Lambda U$ と固有値分解できる（$U\\in\\mathbb{R}^{D\\times D}$）。\n",
    "$V\\in\\mathbb{R}^{K\\times D}, VV^\\top = I$ を一つ持ってくる。\n",
    "\n",
    "$W=VU^\\top\\in\\mathbb{R}^{K\\times D}$と置くと、\n",
    "- $VAV^\\top = VU^\\top\\Lambda U V^\\top = W\\Lambda W^\\top$.\n",
    "- $W$ の各行は$D$次元空間の正規直交基底: $WW^\\top = UV^\\top VU^\\top = I$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{tr}(W\\Lambda W^\\top) = \\sum_{d=1}^D \\lambda_d \\sum_{k=1}^Kw_{k,d}^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_d:=\\sum_{k=1}^K w_{k,d}^2$ と置くと、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{tr}(W\\Lambda W^\\top) &= \\sum_{d=1}^D \\lambda_d \\sum_{k=1}^Kw_{k,d}^2\\\\\n",
    "&= \\sum_{d=1}^D \\lambda_d w_d\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "ここで $0\\leq\\sum_{k=1}^K w_{k,d}^2 \\leq 1~(d=1,\\dots,D)$, $\\sum_{d=1}^D \\sum_{k=1}^K w_{k,d}^2=K$ なので、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{tr}(W\\Lambda W^\\top) &= \\sum_{d=1}^D \\lambda_d w_d\\\\\n",
    "&\\leq \\max_{w_d\\in[0,1], \\sum_{d=1}^D w_d\\leq K}\\sum_{d=1}^D \\lambda_d w_d\n",
    "\\end{align}\n",
    "$$\n",
    "が成立。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定理\n",
    "$A=\\sum_{n=1}^N x_n x_n^\\top$ として、その固有値、固有ベクトルを $\\lambda_1,\\dots, \\lambda_D$, $u_1,\\dots,u_D$ とする（$\\lambda_1\\geq\\lambda_2\\geq\\cdots\\geq\\lambda_D$）。\n",
    "\n",
    "この時 $V = \\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top$ が最適化問題(2), (3)の解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明\n",
    "\n",
    "$$\n",
    "\\mathrm{tr}(VAV^\\top) = \\mathrm{tr}(VU^\\top \\Lambda UV^\\top) = \\mathrm{tr}(\\mathbb{1}_K \\Lambda \\mathbb{1}_K) = \\sum_{d=1}^K \\lambda_d\n",
    "$$\n",
    "が成り立つ。ここで\n",
    "$$\n",
    "[\\mathbb{1}_K]_{i,j} =\n",
    "\\begin{cases}\n",
    "\\delta_{i,j} &\\text{ if } i=j\\leq K\\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "補題3より、これは最適値。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
