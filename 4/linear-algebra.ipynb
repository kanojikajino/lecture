{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 応用計量分析２（第4回）\n",
    "\n",
    "線形代数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 担当教員: 梶野 洸（かじの ひろし）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本日の目標\n",
    "\n",
    "- 線形代数を思い出す\n",
    "- Python で線形代数の数値計算をやる\n",
    "- 主成分分析（PCA）を実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形代数で使うオブジェクト\n",
    "\n",
    "- ベクトル $x = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # \n",
    "x = np.array([1.0, 0.0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# なぜ `numpy` を使うか？\n",
    "- それぞれリストでも書けるがリストだと演算が定義されていない。\n",
    "    - ベクトルの足し算\n",
    "    - 行列の掛け算など\n",
    "- `numpy` では `array` の間の演算として定義されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベクトル\n",
    "$x=\\begin{bmatrix}1 \\\\ 0 \\end{bmatrix}$, $y=\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$ とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 0])\n",
    "y = np.array([0, 1.0])\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベクトルのスカラー倍: $3x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3 * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベクトル同士の足し算・引き算: $x + y$, $x - y$\n",
    "- より一般的に線形結合: $3x - 10y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x + y)\n",
    "print(x - y)\n",
    "print(3 * x - 10 * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 内積: $x \\cdot y$, $(3x - y) \\cdot (x+2y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x @ y)\n",
    "print((3 * x - y) @ (x + 2 * y))\n",
    "\n",
    "print(np.dot(x, y)) # 関数の形で書くこともできる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※内積は、2つベクトルを受け取って、1つのスカラーを返す**関数**としても書ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノルム: $\\|2x - y\\|_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((2 * x - y) @ (2 * x - y)) ** (0.5)) # 内積を使って計算した場合\n",
    "print(np.linalg.norm(2 * x - y)) # numpyの関数を使って計算した場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 要素積（アダマール積）: $x\\circ y$\n",
    "\n",
    "各次元で積を取る演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "- ベクトルはnumpyの `array` というオブジェクトで定義する\n",
    "- 普通の数値と同じような演算ができる\n",
    "- 内積やノルムなど、線形代数特有の計算は**関数**を用いて計算する\n",
    "    - 内積: `np.dot`\n",
    "    - ノルム: `np.linalg.norm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 想定QA\n",
    "\n",
    "Q. 欲しい関数があるかどうか調べたい\n",
    "\n",
    "A. ググるかライブラリのAPIを見る（numpyは[ここ](https://docs.scipy.org/doc/numpy/reference/)）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. `np.dot` とか `np.linalg.norm` とかなんやねん\n",
    "\n",
    "A. ライブラリは階層構造になっている。\n",
    "- `np.dot` は、`numpy` (`np`と書いてる)直下に定義された `dot` という関数、\n",
    "- `np.linalg.norm` は、`numpy` の下の `linalg` (linear algebra; 線形代数)という線形代数の関数をまとめた集まりのなかの `norm` という関数\n",
    "と解釈する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. じゃあ `np.array` は？\n",
    "\n",
    "A. オブジェクトを作る関数と言ってもいいかも。\n",
    "\n",
    "リストを受け取って `array` を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列\n",
    "$A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 2 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array にリストのリストを渡すと行列\n",
    "A = np.array([[1.0, 1.0], [0.0, 2.0]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列とベクトルの積\n",
    "$Ax$\n",
    "\n",
    "$x^\\top A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A @ x)\n",
    "print(x @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A @ np.array([1,2,3,4])) # 2x2の行列に4次元のベクトルは掛けられない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列と行列の積\n",
    "$A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 2 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 & 1 \\\\ 1 & 2 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.0, 1.0],\n",
    "              [0.0, 2.0]])\n",
    "B = np.array([[0.0, 1.0],\n",
    "              [1.0, 2.0]])\n",
    "print(A @ B)\n",
    "print(B @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "\n",
    "- $A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}$ の絶対値が最大の固有値とそれに対応する固有ベクトルを計算せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指針\n",
    "\n",
    "1. 手計算\n",
    "1. `numpy` で実装されているのをつかう\n",
    "1. べき乗法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.eigvals(np.array([[2,1],[1,2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手計算\n",
    "\n",
    "- 固有値、固有ベクトルの定義: $A v = \\lambda v$ を満たす $\\lambda$, $v (\\neq 0)$\n",
    "- 線形方程式 $(A - \\lambda I)v = 0$ が非自明な解（つまり$v\\neq 0$）を持つような $\\lambda$ を見つければよい\n",
    "- 特性方程式 $\\mathrm{det}(A-\\lambda I)=0$ の解が固有値\n",
    "- $\\mathrm{det}(A-\\lambda I) = (2-\\lambda)(2-\\lambda)-1 \\\\= \\lambda^2 - 4\\lambda + 3 = (\\lambda-3)(\\lambda - 1)=0$\n",
    "- 絶対値が最大の固有値は $3$\n",
    "- $(A - \\lambda I)v = \\begin{bmatrix} -1 & 1\\\\1 & -1 \\end{bmatrix}\\begin{bmatrix}v_1\\\\ v_2 \\end{bmatrix}=0$\n",
    "- $v_1 = v_2$ を満たせばよいので、例えば $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ が固有ベクトル。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `numpy` で実装されているのを使う\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 1], [1, 2]])\n",
    "np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "絶対値最大の固有値は $3$、対応する固有ベクトルは $\\begin{bmatrix}0.70710678\\\\ 0.70710678 \\end{bmatrix}$\n",
    "\n",
    "（返り値の解釈は、[API](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html)を見ましょう）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# べき乗法\n",
    "\n",
    "- $A\\in\\mathbb{R}^{N\\times N}$ の固有値と対応する固有ベクトルを $\\lambda_1,\\dots,\\lambda_N$, $v_1,\\dots,v_N$ とする。\n",
    "- $|\\lambda_1| > |\\lambda_2| > \\cdots > |\\lambda_N|$ とする。\n",
    "\n",
    "任意のベクトル $x\\in\\mathbb{R}^N$ は、固有ベクトルで展開できる（固有ベクトルは基底を成す）:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "x = \\sum_{n=1}^{N}c_n v_n\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ を掛け続けると絶対値最大の固有値に対応する固有ベクトルが（相対的に）強調される:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "A^k x &= \\sum_{n=1}^{N}c_n A^k v_n = \\sum_{n=1}^N c_n \\lambda_n^k v_n\\\\\n",
    "&= \\lambda_1^k \\sum_{n=1}^N c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^k v_n\\\\\n",
    "&\\approx \\lambda_1^k c_1 v_1\n",
    "\\end{eqnarray}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 適当なベクトルに行列 $A$ を掛け続けると $v_1$ が求まる\n",
    "- $\\lambda_1 = \\dfrac{v_1^\\top A v_1}{v_1^\\top v_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 1], [1, 2]])\n",
    "x = np.array([1, 2])\n",
    "for _ in range(100):\n",
    "    x = A @ x\n",
    "    x = x / np.linalg.norm(x) # ベクトルを正規化しないと数値誤差が乗る\n",
    "print(x@A@x / (x@x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形方程式\n",
    "\n",
    "$A\\in\\mathbb{R}^{N\\times N}$, $b\\in\\mathbb{R}^N$ としたとき、\n",
    "$Ax=b$ を満たす $x\\in\\mathbb{R}^N$ を求める。\n",
    "\n",
    "$A$ が正則行列（＝逆行列を持つ）のとき、 $x = A^{-1}b$ が解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二通りの実装方法がある\n",
    "- 逆行列を求めるアルゴリズム(Gauss-Jordanなど)を利用\n",
    "- 直接線形方程式を解くアルゴリズム(LU分解)を利用\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "！！なるべく直接線形方程式を解くアルゴリズムを利用すべき！！\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LU 分解の方がそもそも速い\n",
    "    - $A$ の形によっては更に速くなる\n",
    "- `numpy` では逆行列を求めるのに$AX=I$を解いている（＝線形方程式を解くのと同じ計算時間がここで必要）\n",
    "    - さらに $A^{-1}b$ を計算しないといけないので計算時間的に損\n",
    "\n",
    "（参考）伊理正夫, 藤野和建: 数値計算の常識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "\n",
    "- ベクトル、行列は `numpy` を使う\n",
    "- 固有値・固有ベクトルなどの計算もできる\n",
    "- 線形方程式も解ける\n",
    "- 逆行列を求める必要があるか考える（線形方程式を解けばいい場合は線形方程式を解く）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主成分分析, PCA\n",
    "\n",
    "データ $x_1,\\dots,x_N\\in \\mathbb{R}^D$ があったとき、その\"特性\"を保ったまま低次元表現を得たい。\n",
    "- データを目で見たい（100次元だと見られないけど2次元なら）\n",
    "- 同じ情報量ならば低次元の方が学習しやすい\n",
    "- 特性の定義によって様々な手法がある\n",
    "- $K~(<D)$次元表現を得る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA は、次のような線形変換のペア $W, U$ を求めるという気持ち:\n",
    "- 入力 $x\\in\\mathbb{R}^D$\n",
    "- 低次元表現 $z = Wx$ ($W\\in\\mathbb{R}^{K\\times D}$)\n",
    "- 低次元表現から入力を復元 $\\hat{x} = U^\\top z = U^\\top W x$ ($U\\in\\mathbb{R}^{K\\times D}$)\n",
    "- $\\hat{x}\\approx x$ となってほしい\n",
    "<img src=\"figs/pca.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定式化\n",
    "- $X = \\begin{bmatrix} x_1 & x_2 & \\dots & x_N \\end{bmatrix}^\\top$\n",
    "- 平均$0$であるとする: $\\sum_{n=1}^N x_n = 0$\n",
    "- 以下を満たす $W, U$ を求める\n",
    "\n",
    "$$\n",
    "\\min_{W, U\\in\\mathbb{R}^{K\\times D}} \\sum_{n=1}^{N}\\|x_n - U^{\\top}Wx_n\\|_{2}^2 \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補題1\n",
    "\n",
    "式(1)の最適値は\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{V\\in\\mathbb{R}^{K\\times D},\\ VV^\\top=I} \\sum_{n=1}^{N}\\|x_n - V^{\\top}Vx_n\\|_{2}^2\\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "の最適値と等しい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 証明\n",
    "- $R = \\{U^\\top W x \\mid x \\in \\mathbb{R}^D\\}$ とすると、$R$は$\\mathbb{R}^D$中の$K$次元線型部分空間\n",
    "- $R$ の正規直交基底を$V=\\begin{bmatrix}v_1 & \\dots & v_K\\end{bmatrix}^\\top\\in\\mathbb{R}^{D\\times K}$とする。\n",
    "- $V^\\top Vx = \\arg\\min_{\\tilde{x}\\in R} \\|x - \\tilde{x}\\|$が成り立つ。\n",
    "    - $R$ の元は $y\\in\\mathbb{R}^K$ を用いて $V^\\top y$ と書けることを利用して示す（演習）\n",
    "- 式(1)の最適解 $U^\\star$, $W^\\star$ と、それに対応する $R^\\star$, $V^\\star$ を持ってくると、\n",
    "$$\n",
    "\\begin{align}\n",
    "\\|x_n - {U^\\star}^\\top W^\\star x_n\\|^2 \\geq \\min_{\\tilde{x}_n\\in R^\\star}\\|x_n - \\tilde{x}_n\\|^2 = \\|x_n - {V^\\star}^\\top V^\\star x_n\\|^2\n",
    "\\end{align}\n",
    "$$\n",
    "- $U^\\star, W^\\star$ も $V^\\star$ も最適解なので、上式は等号成立。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補題2\n",
    "最適化問題(2)は\n",
    "$$\n",
    "\\max_{V\\in\\mathbb{R}^{K\\times D}, VV^\\top=I}\\mathrm{tr}\\left(V \\left(\\sum_{n=1}^N x_n x_n^\\top\\right)V^\\top\\right) \\tag{3}\n",
    "$$\n",
    "と同値。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明\n",
    "\n",
    "展開すれば良い。\n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^N \\|x_n - V^\\top V x_n\\|^2 = \\sum_{n=1}^N \\|x_n\\|^2 - 2\\sum_{n=1}^N x_n^\\top V^\\top V X_n + \\sum_{n=1}^N x_n^\\top V^\\top V V^\\top V x_n\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\sum_{n=1}^N \\|x_n\\|^2 - \\sum_{n=1}^N x_n^\\top V^\\top V x_n\n",
    "$$\n",
    "\n",
    "第二項は、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N x_n^\\top V^\\top V x_n = \\sum_{n=1}^N \\mathrm{tr}(x_n^\\top V^\\top V x_n)\n",
    "=  \\sum_{n=1}^N \\mathrm{tr}(x_n x_n^\\top V^\\top V) \\\\\n",
    "= \\mathrm{tr}\\left(\\left(\\sum_{n=1}^N x_n x_n^\\top\\right) V^\\top V\\right)\n",
    "= \\mathrm{tr}\\left(V\\left(\\sum_{n=1}^N x_n x_n^\\top\\right) V^\\top\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補題3\n",
    "$A=\\sum_{n=1}^N x_n x_n^\\top$ として、その固有値、固有ベクトルを $\\lambda_1,\\dots, \\lambda_D$, $u_1,\\dots,u_D$ とする（$\\lambda_1\\geq\\lambda_2\\geq\\cdots\\geq\\lambda_D$）。\n",
    "この時任意の $V\\in\\mathbb{R}^{K\\times D}, VV^\\top=I$ について\n",
    "\n",
    "$$\n",
    "\\mathrm{tr}\\left(V A V^\\top\\right) \\leq \\max_{w\\in[0,1]^D, \\sum_{d=1}^D w_d\\leq K}\\sum_{d=1}^D \\lambda_d w_d = \\sum_{d=1}^K \\lambda_d\n",
    "$$\n",
    "\n",
    "が成立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明\n",
    "$A=U^\\top \\Lambda U$ と固有値分解できる（$U\\in\\mathbb{R}^{D\\times D}$）。\n",
    "$V\\in\\mathbb{R}^{K\\times D}, VV^\\top = I$ を一つ持ってくる。\n",
    "\n",
    "$W=VU^\\top\\in\\mathbb{R}^{K\\times D}$と置くと、\n",
    "- $VAV^\\top = VU^\\top\\Lambda U V^\\top = W\\Lambda W^\\top$.\n",
    "- $W$ の各行は$D$次元空間の正規直交基底: $WW^\\top = UV^\\top VU^\\top = I$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{tr}(W\\Lambda W^\\top) = \\sum_{d=1}^D \\lambda_d \\sum_{k=1}^Kw_{k,d}^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_d:=\\sum_{k=1}^K w_{k,d}^2$ と置くと、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{tr}(W\\Lambda W^\\top) &= \\sum_{d=1}^D \\lambda_d \\sum_{k=1}^Kw_{k,d}^2\\\\\n",
    "&= \\sum_{d=1}^D \\lambda_d w_d\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "ここで $0\\leq\\sum_{k=1}^K w_{k,d}^2 \\leq 1~(d=1,\\dots,D)$, $\\sum_{d=1}^D \\sum_{k=1}^K w_{k,d}^2=K$ なので、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{tr}(W\\Lambda W^\\top) &= \\sum_{d=1}^D \\lambda_d w_d\\\\\n",
    "&\\leq \\max_{w_d\\in[0,1], \\sum_{d=1}^D w_d\\leq K}\\sum_{d=1}^D \\lambda_d w_d\n",
    "\\end{align}\n",
    "$$\n",
    "が成立.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定理\n",
    "$A=\\sum_{n=1}^N x_n x_n^\\top$ として、その固有値、固有ベクトルを $\\lambda_1,\\dots, \\lambda_D$, $u_1,\\dots,u_D$ とする（$\\lambda_1\\geq\\lambda_2\\geq\\cdots\\geq\\lambda_D$）。\n",
    "\n",
    "この時 $V = \\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top$ が最適化問題(2), (3)の解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明\n",
    "\n",
    "$$\n",
    "\\mathrm{tr}(VAV^\\top) = \\mathrm{tr}(VU^\\top \\Lambda UV^\\top) = \\mathrm{tr}(\\mathbb{1}_K \\Lambda \\mathbb{1}_K) = \\sum_{d=1}^K \\lambda_d\n",
    "$$\n",
    "が成り立つ。ここで\n",
    "$$\n",
    "[\\mathbb{1}_K]_{i,j} =\n",
    "\\begin{cases}\n",
    "\\delta_{i,j} &\\text{ if } i=j\\leq K\\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "補題3より、これは最適値。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アルゴリズム\n",
    "\n",
    "- 入力: $x_1,\\dots, x_N\\in\\mathbb{R}^D$, $K\\in\\mathbb{N}$\n",
    "- 出力: $z_1,\\dots, z_N\\in\\mathbb{R}^K$\n",
    "\n",
    "\n",
    "1. $A=\\sum_{n=1}^N x_n x_n^\\top$\n",
    "1. $A$ の固有値と対応する固有ベクトル $(\\lambda_1, u_1),\\dots,(\\lambda_D, u_D)$ を求める（$\\lambda_1\\geq\\cdots\\geq \\lambda_D$）\n",
    "1. $V=\\begin{bmatrix}u_1 \\dots u_K\\end{bmatrix}^\\top$ として、$z_n=Vx_n$ を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "\n",
    "- PCA はデータを低次元空間に落とす方法\n",
    "- 再構成時の損失を最小化するようにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA の実装\n",
    "\n",
    "- PCA でデータを2次元で見てみる\n",
    "- 主成分を見てみる\n",
    "- 再構成してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# データを取得\n",
    "dataset = fetch_olivetti_faces()\n",
    "num_examples, row_size, col_size = dataset['images'].shape\n",
    "X = dataset['data']\n",
    "\n",
    "# 平均0にしておく（しなくてもまあ大丈夫だけど）\n",
    "X_mean = X.mean(axis=0)\n",
    "X_centered = X - X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顔データを表示してみる\n",
    "plt.imshow(dataset['images'][0], cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "X_centered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "PCA を実行する関数を書け\n",
    "\n",
    "- 入力: データ $X\\in\\mathbb{R}^{N\\times D}$, 次元 $K$\n",
    "- 出力: 変換されたデータ $Z\\in\\mathbb{R}^{N\\times K}$, 変換にもちいる線形変換 $V\\in\\mathbb{R}^{D\\times K}$\n",
    "\n",
    "\n",
    "ヒント: 対称行列の固有値分解を行う関数\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eigh.html#scipy.linalg.eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eigh\n",
    "def pca(X, K):\n",
    "    A = X.T @ X\n",
    "    eig_val, eig_vec = eigh(A)\n",
    "    V = eig_vec[:, -K:]\n",
    "    z = X @ V\n",
    "    return z, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca を実行\n",
    "K=20\n",
    "z, V = pca(X_centered, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V の行ベクトルが正規直交基底であることを確認\n",
    "print('distance from the identity:', np.abs(V.T @ V - np.identity(K)).max())\n",
    "\n",
    "print('mean reconstruction loss: ',((X_centered - z @ V.T) * (X_centered - z @ V.T)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの貼る空間の固有ベクトルを見てみる\n",
    "plt.imshow(-V[:, -1].reshape(row_size, col_size), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z[:, 0], z[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この場合は2次元に落としてもよくわからない...\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, 10))\n",
    "for each_idx in range(100):\n",
    "    plt.scatter(z[each_idx, 0], z[each_idx, 1], color=colors[dataset['target'][each_idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構成\n",
    "X_rec = z @ V.T + X_mean\n",
    "idx = 190\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(dataset['images'][idx], cmap=plt.cm.gray) # 左が元の画像\n",
    "ax2.imshow(X_rec[idx].reshape(row_size, col_size), cmap=plt.cm.gray) # 右が再構成画像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "\n",
    "- 行列、ベクトルは `numpy` を使って実装する\n",
    "- 線形代数の操作は `numpy` の API を探せば実装されていることが多い\n",
    "- 主成分分析(principle component analysis; PCA) を実装した\n",
    "    - データを低次元空間に射影するアルゴリズム\n",
    "    - 再構成時の損失を最小化する\n",
    "    - 固有値分解に帰着される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
