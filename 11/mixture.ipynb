{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 応用計量分析２（第11回）\n",
    "混合分布モデルとEMアルゴリズム\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 担当教員: 梶野 洸（かじの ひろし）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 最尤推定\n",
    "\n",
    "$$\n",
    "\\theta^\\star = \\arg\\max_{\\theta\\in\\Theta}p(\\mathcal{D} ; \\theta)\n",
    "$$\n",
    "をパラメタの推定値とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "各データの独立同分布性を仮定すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(\\mathcal{D}; \\theta) &= \\sum_{n=1}^N \\log p(x_n; \\theta)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "モデルの仮定では、 $p(x;\\theta) = \\sum_{z=1}^{K}p(x \\mid z;\\theta)p(z;\\theta)$ だったので、上式は、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N \\log \\left( \\sum_{z_n=1}^{K} p(x_n \\mid z_n; \\theta)p(z_n;\\theta)\\right)\\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "最尤推定量は式(1)を最大化することで求まる。\n",
    "\n",
    "最大化の手法は二種類\n",
    "\n",
    "1. 勾配法で式(1)を直接最大化する\n",
    "1. EMアルゴリズムで最大化する（今回はこっち！）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expectation-maximization (EM) アルゴリズム\n",
    "隠れ変数があるモデルの最尤推定量を求めるアルゴリズム\n",
    "\n",
    "- 現状は各データの隠れ変数 $z_n$ もパラメタ $\\theta$ もわからない\n",
    "    1. $z_n$ が1つに決まれば $\\theta$ がわかる\n",
    "    1. $\\theta$ が1つに決まれば $z_n$ がわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- とりあえずどちらかを初期化して、1, 2 を繰り返せばいい感じの $z_n$, $\\theta$ が求まりそう\n",
    "    - 局所最適解が求まることが示せる\n",
    "    - （大域的最適解を求めるのはそもそも難しいので諦めている）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EM アルゴリズムの利点\n",
    "\n",
    "- EステップとMステップが解析的に書ける\n",
    "    - 毎ステップで尤度が下がらないことが保証される\n",
    "    - 勾配法だと、ステップサイズによって尤度が下がることもある\n",
    "- より難しいモデルの推定にも同じようなアイデアが適用できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 演習\n",
    "\n",
    "1. $X_n$ の実現値だけでなく $Z_n$ の実現値も得られていた場合の最尤推定量 $\\theta^\\star$ を計算せよ\n",
    "    - $(x_n, z_n)$ が $p(x, z;\\theta)= \\pi_{z}\\mathcal{N}(x; \\mu_z, \\Sigma_z)$ という同時分布に従っている\n",
    "    - $-\\sum_{n=1}^{N}\\log p(x_n, z_n;\\theta)$ を $\\theta$ について最小化する\n",
    "1. $X_n$ の実現値だけでなく、パラメタ$\\theta^\\star$の値もわかっている場合の隠れ変数の事後分布を計算せよ\n",
    "    - $p(z_n \\mid x_n; \\theta^\\star)$ を計算する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 答え\n",
    "\n",
    "1. $\\{(x_n, z_n)\\}_{n=1}^N$ が得られていた場合、$x_n, z_n$ の同時分布は、\n",
    "\n",
    "$$\n",
    "p(x_n, z_n; \\theta) = \\pi_{z_n} \\mathcal{N}(x_n; \\mu_{z_n}, \\Sigma_{z_n})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&-\\sum_{n=1}^{N}\\log p(x_n, z_n;\\theta) \\\\\n",
    "=& -\\sum_{n=1}^N  \\sum_{k=1}^K \\mathbb{1}[z_n=k]\\left(\\log\\pi_{k} + \\log\\mathcal{N}(x_n; \\mu_{k}, \\Sigma_{k})\\right)\\\\\n",
    "=&\\sum_{n=1}^N \\sum_{k=1}^K \\mathbb{1}[z_n=k]\\left(-\\log\\pi_{k} + \\dfrac{1}{2}(x_n - \\mu_{k})^\\top \\Sigma_{k}^{-1} (x_n - \\mu_{k})\\right.\\\\\n",
    "&\\hspace{5cm} \\left.+ \\dfrac{D}{2}\\log 2\\pi + \\dfrac{1}{2}\\log\\det\\Sigma_{k}\\right)\\tag{2}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\mu_k$ についての最大化\n",
    "\n",
    "式(2)を$\\mu_k$で微分すると\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\mathbb{1}[z_n=k]\\Sigma_{k}^{-1}(x_n - \\mu_k)\n",
    "$$\n",
    "なので、$\\mu_k$の最尤推定量は\n",
    "$$\n",
    "\\mu_k^{\\star} = \\dfrac{\\sum_{n=1}^N \\mathbb{1}[z_n=k]x_n}{\\sum_{n=1}^N \\mathbb{1}[z_n=k]}\n",
    "$$\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\Sigma_k$ についての最大化\n",
    "\n",
    "式(2)を$\\Sigma_k$で微分すると\n",
    "\n",
    "$$\n",
    "\\dfrac{1}{2}\\sum_{n=1}^N \\mathbb{1}[z_n=k]\\left(-\\Sigma_k^{-1}(x_n - \\mu_k)(x_n - \\mu_k)^\\top\\Sigma_k^{-1} + \\Sigma_k^{-1}\\right)\n",
    "$$\n",
    "\n",
    "なので、$\\Sigma_k$の最尤推定量は\n",
    "\n",
    "$$\n",
    "\\Sigma_k^\\star = \\dfrac{\\sum_{n=1}^{N}\\mathbb{1}[z_n=k](x_n - \\mu_k^\\star)(x_n-\\mu_k^\\star)^\\top}{\\sum_{n=1}^{N}\\mathbb{1}[z_n=k]}\n",
    "$$\n",
    "\n",
    "となる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\pi_k$ についての最大化\n",
    "\n",
    "$\\pi_k$ は $\\sum_{k=1}^{K}\\pi_k=1$ を満たす必要があるため、\n",
    "式(2)に$\\lambda \\left(\\sum_{k=1}^K \\pi_k - 1\\right)$を足したものを$\\pi_k$で微分して\n",
    "$$\n",
    "\\sum_{n=1}^N \\mathbb{1}[z_n=k]\\left(-\\dfrac{1}{\\pi_k^\\star}\\right) + \\lambda=0\n",
    "$$\n",
    "を解けば良い。\n",
    "$$\n",
    "\\lambda \\pi_k^{\\star} = \\sum_{n=1}^N \\mathbb{1}[z_n=k]\n",
    "$$\n",
    "を $k=1,\\dots,K$ で足すと\n",
    "$$\n",
    "\\lambda = N.\n",
    "$$\n",
    "よって、\n",
    "$$\n",
    "\\pi_k^{\\star} = \\dfrac{\\sum_{n=1}^N \\mathbb{1}[z_n=k]}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(2) $p(z \\mid x; \\theta) \\propto p(x \\mid z; \\theta)p(z; \\theta)$ なので、\n",
    "\n",
    "$$\n",
    "p(z_n \\mid x_n;\\theta^\\star) = \\dfrac{\\pi_{z_n}^{\\star}\\mathcal{N}(x_n; \\mu_{z_n}^{\\star}, \\Sigma_{z_n}^{\\star})}{\\sum_{k=1}^K\\pi_{k}^{\\star}\\mathcal{N}(x_n; \\mu_{k}^{\\star}, \\Sigma_{k}^{\\star})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 演習まとめ\n",
    "\n",
    "$z_n$ が1つに決まっていると、\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N \\log \\left( \\sum_{z_n=1}^{K} p(x_n \\mid z_n; \\theta)p(z_n;\\theta)\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "の log のなかの足し算がなくなって、\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N \\left(\\log p(x_n \\mid z_n; \\theta) + \\log p(z_n;\\theta)\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "の最大化となるため、解析的に解ける。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EMアルゴリズムの導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EM アルゴリズムの導出\n",
    "\n",
    "任意の分布 $q(z)$ について\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\log \\left(\\sum_{z}p(x\\mid z; \\theta) p(z;\\theta)\\right)\\\\\n",
    "= &\\log \\left(\\sum_{z}p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}q(z)\\right)\\\\\n",
    "\\geq & \\sum_{z}q(z)\\log \\left(p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}\\right)\\\\\n",
    "= &\\sum_{z}q(z)\\left(\\log p(x, z; \\theta) - \\log{q(z)}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "が成り立つことを利用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 証明（演習）\n",
    "\n",
    "- $f\\colon \\mathbb{R}^D \\rightarrow \\mathbb{R}$: 任意の凸関数\n",
    "- $x_1,\\dots,x_N\\in\\mathbb{R}^D$ : $f$ の定義域の任意の$N$点\n",
    "- $w_1,\\dots,w_N\\in[0,1]$ s.t. $\\sum_{n=1}^N w_n = 1$ : 任意の重み\n",
    "\n",
    "とする。\n",
    "\n",
    "$$\n",
    "f\\left(\\sum_{n=1}^N w_n x_n\\right)\\leq \\sum_{n=1}^N w_n f\\left(x_n\\right)\n",
    "$$\n",
    "を示せ (Jensenの不等式)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ヒント\n",
    "$f: \\mathbb{R}^{D}\\rightarrow\\mathbb{R}$ が凸関数 $\\Longleftrightarrow$ 任意の$x_1, x_2\\in\\mathbb{R}^D$, $w_1, w_2\\in[0,1]$ s.t. $w_1 + w_2=1$ について\n",
    "$$\n",
    "f(w_1 x_1 + w_2 x_2) \\leq w_1 f(x_1) + w_2 f(x_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$N$ の時に成り立っているとして、$N+1$の時にも成り立つことを示す。\n",
    "$$\n",
    "\\begin{align}\n",
    "& f\\left(\\sum_{n=1}^{N+1} w_n x_n\\right) \\\\\n",
    "=& f\\left(w_{N+1}x_{N+1} + \\sum_{n=1}^N w_n x_n\\right)\\\\\n",
    "=&f\\left(w_{N+1}x_{N+1} + (1-w_{N+1})\\sum_{n=1}^N {w_n}\\dfrac{x_n}{1-w_{N+1}} \\right)\\\\\n",
    "\\leq & w_{N+1}f(x_{N+1}) + (1-w_{N+1})f\\left(\\sum_{n=1}^N \\dfrac{w_n}{1-w_{N+1}}x_n\\right)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\leq & w_{N+1}f(x_{N+1}) + (1-w_{N+1})\\sum_{n=1}^N \\dfrac{w_n}{1-w_{N+1}}f\\left(x_n\\right)\\ \\ \\left(\\text{note that}\\sum_{n=1}^N \\dfrac{w_n}{1-w_{N+1}}=1\\right)\\\\\n",
    "= &\\sum_{n=1}^{N+1}w_n f(x_n)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 再掲\n",
    "\n",
    "$\\log x$ は凹関数なので、任意の分布 $q(z)$ について\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\log \\left(\\sum_{z}p(x\\mid z; \\theta) p(z;\\theta)\\right)\\\\\n",
    "= &\\log \\left(\\sum_{z}p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}q(z)\\right)\\\\\n",
    "\\geq & \\sum_{z}q(z)\\log \\left(p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}\\right)\\\\\n",
    "= & \\sum_{z}q(z)\\left(\\log p(x, z; \\theta) - \\log{q(z)}\\right) \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "が成り立つ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EMアルゴリズムの導出\n",
    "\n",
    "尤度（式(3)の左側）を最大化する代わりに尤度の下界（式(3)の右側）を最大化する:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\sum_{z_n}q(z_n)(\\log p(x_n, z_n; \\theta) - \\log q(z_n))\n",
    "$$\n",
    "\n",
    "- $q$ に関する最大化\n",
    "- $\\theta$ に関する最大化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $q$ を固定して $\\theta$ に関して最大化\n",
    "\n",
    "$$\n",
    "p(x_n, z_n; \\theta) = \\pi_{z_n} \\mathcal{N}(x_n; \\mu_{z_n}, \\Sigma_{z_n})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& -\\sum_{n=1}^{N}\\sum_{k=1}^K q(z_n=k)\\log p(x_n, z_n=k;\\theta) \\\\\n",
    "=& -\\sum_{n=1}^N \\sum_{k=1}^K q(z_n=k)\\left(\\log\\pi_{k} + \\log\\mathcal{N}(x_n; \\mu_{k}, \\Sigma_{k})\\right)\\\\\n",
    "=& \\sum_{n=1}^N \\sum_{k=1}^K q(z_n=k)\\left(-\\log\\pi_{k} + \\dfrac{1}{2}(x_n - \\mu_{k})^\\top \\Sigma_{k}^{-1} (x_n - \\mu_{k})\\right.\\\\\n",
    "& \\hspace{5cm} \\left. + \\dfrac{D}{2}\\log 2\\pi + \\dfrac{1}{2}\\log\\det\\Sigma_{k}\\right)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "式(2)で $\\mathbb{1}[z_n=k]$ を $q(z_n=k)$ に変えたやつだ！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "よって\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_k^{\\star} &= \\dfrac{\\sum_{n=1}^N q(z_n=k)x_n}{\\sum_{n=1}^N q(z_n=k)}\\\\\n",
    "\\Sigma_k^\\star &= \\dfrac{\\sum_{n=1}^{N}q(z_n=k)(x_n - \\mu_k^\\star)(x_n-\\mu_k^\\star)^\\top}{\\sum_{n=1}^{N}q(z_n=k)}\\\\\n",
    "\\pi_k^{\\star} &= \\dfrac{\\sum_{n=1}^N q(z_n=k)}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\theta$ を固定して $q$ に関して最大化\n",
    "\n",
    "$q$ は $\\sum_{k=1}^K q(z_n=k)=1~(n=1,\\dots,N)$ を満たす $N\\times K$ 個の実数からなる。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\dfrac{\\partial}{\\partial q(z_n=k)}\\left(\\sum_{n=1}^{N}\\sum_{k=1}^K q(z_n=k) \\right.\\\\\n",
    "& \\hspace{3cm} \\times (\\log p(x_n, z_n=k; \\theta) - \\log q(z_n=k)) \\\\\n",
    "& \\hspace{3cm} \\left. + \\sum_{n=1}^N\\lambda_n \\left(\\sum_{k=1}^K q(z_n=k) - 1\\right)\\right)\\\\\n",
    "=&\\log p(x_n, z_n=k;\\theta) - \\log q(z_n=k) - 1 + \\lambda_n = 0\n",
    "\\end{align}\n",
    "$$\n",
    "を解くと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "q(z_n=k) &= \\dfrac{p(x_n, z_n=k;\\theta)}{\\sum_{k=1}^K p(x_n, z_n=k;\\theta)} \\\\\n",
    "&= \\dfrac{\\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EM アルゴリズム\n",
    "\n",
    "- $\\mu_k, \\Sigma_k, \\pi_k~(k=1,\\dots,K)$ を適当に初期化\n",
    "- 以下を繰り返す:\n",
    "    - E-step: for each $n=1,\\dots,N, k=1,\\dots,K$,\n",
    "    $$q(z_n=k)\\leftarrow \\dfrac{\\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}$$\n",
    "    - M-step: for each $k=1,\\dots,K$,\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\mu_k &\\leftarrow \\dfrac{\\sum_{n=1}^N q(z_n=k)x_n}{\\sum_{n=1}^N q(z_n=k)}\\\\\n",
    "\\Sigma_k &\\leftarrow \\dfrac{\\sum_{n=1}^{N}q(z_n=k)(x_n - \\mu_k)(x_n-\\mu_k)^\\top}{\\sum_{n=1}^{N}q(z_n=k)}\\\\\n",
    "\\pi_k &\\leftarrow \\dfrac{\\sum_{n=1}^N q(z_n=k)}{N}\n",
    "\\end{align}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "適当な終了条件で繰り返しをやめる\n",
    "\n",
    "- 尤度の増分が一定以下になった\n",
    "- パラメタの変化幅が一定以下になった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EMアルゴリズムまとめ\n",
    "\n",
    "- 変分法を用いて尤度の下界を求めた\n",
    "    - $\\sum_{n=1}^{N}\\sum_{z_n}q(z_n)\\log p(x_n, z_n; \\theta)$ みたいな形を出したかった\n",
    "    - $q$ と $\\theta$ を交互に最適化するとそれぞれ解析的に解ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EMアルゴリズムの実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 演習\n",
    "混合ガウスモデルの場合、\n",
    "\n",
    "- 内部状態\n",
    "- 欲しい命令\n",
    "\n",
    "は何か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 一つの答え\n",
    "\n",
    "- 内部状態\n",
    "    - 正規分布の平均、分散共分散行列 $\\times K$個\n",
    "    - 重み $\\pi=\\begin{bmatrix}\\pi_1 &\\dots & \\pi_K \\end{bmatrix}$\n",
    "- 命令\n",
    "    - データを入力して、パラメタを最尤推定する\n",
    "    - データを入力して、各データの潜在変数を推定する（現状の内部状態を使って）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 他の答え\n",
    "補助的なものを持っていてもよい\n",
    "\n",
    "- 内部状態\n",
    "    - 正規分布の平均、分散共分散行列 $\\times K$個\n",
    "    - 重み $\\pi=\\begin{bmatrix}\\pi_1 &\\dots & \\pi_K \\end{bmatrix}$\n",
    "    - __混合数 $K$ を陽に持っておくと何かと便利__\n",
    "- 命令\n",
    "    - データを入力して、パラメタを最尤推定する\n",
    "        - __E ステップを実行する__\n",
    "        - __M ステップを実行する__\n",
    "        - __尤度を計算する__\n",
    "    - データを入力して、各データの潜在変数を推定する（現状の内部状態を使って）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 他の答え2\n",
    "内部状態として他のクラスのオブジェクトを持っていてもよい\n",
    "\n",
    "- 正規分布クラス\n",
    "    - 内部状態\n",
    "        - 平均\n",
    "        - 分散共分散行列\n",
    "    - 命令\n",
    "        - データを入力して、パラメタを最尤推定する\n",
    "        - データを入力して、尤度を計算する\n",
    "\n",
    "- GMM クラス\n",
    "    - 内部状態\n",
    "        - 正規分布オブジェクト $\\times K$個\n",
    "        - 重み $\\pi=\\begin{bmatrix}\\pi_1 &\\dots & \\pi_K \\end{bmatrix}$\n",
    "        - __混合数 $K$ を陽に持っておくと何かと便利__\n",
    "    - 命令\n",
    "        - データを入力して、パラメタを最尤推定する\n",
    "            - __E ステップを実行する__\n",
    "            - __M ステップを実行する__\n",
    "            - __尤度を計算する__\n",
    "        - データを入力して、各データの潜在変数を推定する（現状の内部状態を使って）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python での実装\n",
    "\n",
    "まずは正規分布クラスを実装してみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 課題\n",
    "\n",
    "正規分布クラスを実装せよ（以前の資料からコピペでOK）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Gaussian:\n",
    "    def __init__(self, dim):\n",
    "        '''コンストラクタ（みたいなもの）\n",
    "        オブジェクトを作るときに初めに実行される。\n",
    "        内部状態の初期化に使う\n",
    "        '''\n",
    "        self.dim = dim\n",
    "        '''\n",
    "        self = オブジェクトを指す。 self.dim は、オブジェクトの dim という変数を指す。\n",
    "        上の命令は、 self.dim に dim の値を代入することを表す\n",
    "        '''\n",
    "        self.set_mean(np.random.randn(dim)) # オブジェクトの mean という変数をランダムに初期化\n",
    "        self.set_cov(np.identity(dim))\n",
    "        \n",
    "    def log_pdf(self, X):\n",
    "        ''' 確率密度関数の対数を返す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        log_pdf : array, shape (sample_size,)\n",
    "        '''\n",
    "        if X.shape[1] != self.dim: # 入力の形をチェックしています\n",
    "            raise ValueError('X.shape must be (sample_size, dim)')\n",
    "        return -0.5 * np.sum((X - self.mean) * (np.linalg.solve(self.cov, (X - self.mean).T).T), axis=1) \\\n",
    "            -0.5 * self.dim * np.log(2.0 * np.pi) - 0.5 * np.linalg.slogdet(self.cov)[1]\n",
    "\n",
    "    def fit(self, X):\n",
    "        ''' X を使って最尤推定をする\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        '''\n",
    "        if X.shape[1] != self.dim: # 入力の形をチェックしています\n",
    "            raise ValueError('X.shape must be (sample_size, dim)')\n",
    "        self.set_mean(np.mean(X, axis=0))\n",
    "        self.set_cov((X - self.mean).T @ (X - self.mean) / X.shape[0])\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        ''' 現状のパラメタを使って `sample_size` のサイズのサンプルを生成する\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        sample_size : int\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "            各行は平均 `self.mean`, 分散 `self.cov` の正規分布に従う\n",
    "        '''\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, size=sample_size)\n",
    "        \n",
    "    def set_mean(self, mean):\n",
    "        if mean.shape != (self.dim,):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        self.mean = mean\n",
    "    \n",
    "    def set_cov(self, cov):\n",
    "        if cov.shape != (self.dim, self.dim):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        if np.linalg.eigvalsh(cov)[0] <= 0:\n",
    "            raise ValueError('covariance matrix must be positive semidefinite.')\n",
    "        self.cov = cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 課題\n",
    "- GMM クラスの `__init__` を書いてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        self.gaussian_list = []\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm のオブジェクトができた\n",
    "gmm = GMM(2, 10)\n",
    "for each_gaussian in gmm.gaussian_list:\n",
    "    print(each_gaussian.mean)\n",
    "print(gmm.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "以降、EMアルゴリズムでパラメタ推定をする `fit` を書きたい\n",
    "\n",
    "- `log_pdf`: 現在のパラメタを用いてサンプルの対数尤度を計算するメソッド\n",
    "- `e_step`: Eステップを実行するメソッド\n",
    "- `m_step`: Mステップを実行するメソッド\n",
    "\n",
    "の3つを実装し、これらを組み合わせて `fit` を書く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 課題\n",
    "\n",
    "- サンプルの対数尤度を計算するメソッド `log_pdf` を `GMM` に実装せよ\n",
    "    - 引数: `X`: サンプルサイズ$\\times$次元の行列\n",
    "    - 返り値: $\\begin{bmatrix}\\log p(x_1; \\theta) & \\dots & \\log p(x_N; \\theta)\\end{bmatrix}$ ($\\theta$は現在の内部状態を用いる)\n",
    "    $$\n",
    "    p(x_n; \\theta) = \\sum_{k=1}^K \\pi_{k} \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self. dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        '''\n",
    "        ここで現在の内部状態での likelihood を計算する\n",
    "        \n",
    "        ** ヒント **\n",
    "        self.gaussian_list の各要素は Gaussian クラスのオブジェクト\n",
    "        各データの対数尤度を計算する log_pdf という命令が実装してあった\n",
    "        '''\n",
    "        return np.log(likelihood) # 対数尤度が欲しいので対数をとる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ヒント\n",
    "\n",
    "- `self.gaussian_list[0].log_pdf(X)` はサンプル `X` のデータそれぞれに対する対数尤度を計算する\n",
    "    - `X` が `sample_size` x `dim` とすると、返り値は長さ `sample_size` の配列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `self.weight[0]` は $p(z=0; \\theta)$ に対応する\n",
    "- `self.weight[0] * np.exp(self.gaussian_list[0].log_pdf(X))` は `np.exp(self.gaussian_list[0].log_pdf(X))` の各要素に `self.weight[0]` を掛けた値を返す\n",
    "    - `スカラー * 配列` と書くと、配列の各要素にスカラーを掛けてくれる（`numpy` の記法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self. dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gmm = GMM(2, 10)\n",
    "gmm.log_pdf(np.random.randn(100, 2)) # とりあえず何か計算はできている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 課題\n",
    "- Eステップを実行するメソッド `e_step` を実装せよ\n",
    "    - 引数: データ `X`: `sample_size` $\\times$ `dim` の配列\n",
    "    - 出力: $q(z_n)$\n",
    "        - どのような形式で出力すべきか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- $q(z_n)$ は $K$ 面サイコロだったので、$K$面サイコロの確率分布をデータの数だけ出力すれば良さそう\n",
    "    - $K=$ `n_components`\n",
    "-  `posterior`: `sample_size` $\\times$ `n_components` の配列として出力\n",
    "-  `posterior[n, k]` = $q(z_n=k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "E-step: for each $n=1,\\dots,N, k=1,\\dots,K$,\n",
    "$$q(z_n=k)\\leftarrow \\dfrac{\\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)\n",
    "\n",
    "    def e_step(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        posterior = np.zeros((sample_size, self.num_components))\n",
    "        '''\n",
    "        ここを埋める\n",
    "        \n",
    "        ** ヒント **\n",
    "        各 n について、分母は共通\n",
    "        1. 分子を先に計算して posterior に入れてしまう\n",
    "        2. posterior[n, :].sum() は分母と等しくなる\n",
    "        3. posterior[n, :] = posterior[n, :] / posterior[n, :].sum() とすれば良さそう\n",
    "        '''\n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)\n",
    "\n",
    "    def e_step(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        posterior = np.zeros((sample_size, self.num_components))\n",
    "        # 各コンポーネントで対数尤度が計算できるので、それを利用\n",
    "        for each_component in range(self.num_components):\n",
    "            posterior[:, each_component] \\\n",
    "               = self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        \n",
    "        # まとめて正規化しているが、 for 文でやってもOK（遅くなるけど）\n",
    "        posterior = posterior / posterior.sum(axis=1).reshape(-1, 1)\n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# q はデータがどちらのコンポーネントに近いかを表しているので、\n",
    "# そんな感じの結果になって欲しい\n",
    "gmm = GMM(2, 2)\n",
    "X = gmm.gaussian_list[0].mean.reshape(1, 2)\n",
    "print(gmm.e_step(X))\n",
    "X = gmm.gaussian_list[1].mean.reshape(1, 2)\n",
    "print(gmm.e_step(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 課題\n",
    "- Mステップを実行するメソッド `m_step` を実装せよ\n",
    "    - 引数: \n",
    "        - データ `X`: `sample_size` $\\times$ `dim` の配列\n",
    "        - $q(z_n = k)$ : `sample_size` $\\times$ `n_components`\n",
    "    - 出力: なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "    \n",
    "    def fit(self, X, eps=1e-8):\n",
    "        sample_size = X.shape[0]\n",
    "        converge = False\n",
    "        old_ll = -np.inf\n",
    "        new_ll = -np.inf\n",
    "        while not converge:\n",
    "            posterior = self.e_step(X)\n",
    "            self.m_step(X, posterior)\n",
    "            new_ll = self.log_pdf(X).sum()\n",
    "            if new_ll < old_ll:\n",
    "                raise ValueError('likelihood decreases!')\n",
    "            if np.abs(old_ll - new_ll) / np.abs(new_ll) < eps:\n",
    "                converge = True\n",
    "            old_ll = new_ll\n",
    "        return posterior\n",
    "    \n",
    "    def e_step(self, X):\n",
    "        posterior = np.zeros((X.shape[0], self.num_components))\n",
    "        for each_component in range(self.num_components):\n",
    "            posterior[:, each_component] \\\n",
    "               = self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        posterior = posterior / posterior.sum(axis=1).reshape(-1, 1)\n",
    "        return posterior\n",
    "    \n",
    "    def m_step(self, X, posterior):\n",
    "        self.weight = posterior.sum(axis=0)\n",
    "        for each_component in range(self.num_components):\n",
    "            self.gaussian_list[each_component].set_mean(posterior[:, each_component] @ X / self.weight[each_component])\n",
    "            self.gaussian_list[each_component].set_cov(\n",
    "                (posterior[:, each_component] * (X - self.gaussian_list[each_component].mean).T) \\\n",
    "                @ (X - self.gaussian_list[each_component].mean) / self.weight[each_component])\n",
    "        self.weight = self.weight / np.sum(self.weight)\n",
    "    \n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = np.vstack((np.random.randn(100, 3), np.random.randn(100, 3) + 3))\n",
    "gmm = GMM(3, 2)\n",
    "posterior = gmm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gmm.gaussian_list[0].mean)\n",
    "print(gmm.gaussian_list[1].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "livereveal": {
   "center": false,
   "controls": true,
   "progress": true,
   "scroll": true,
   "slideNumber": true,
   "start_slideshow_at": "selected",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
