{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 応用計量分析２（第6, 7, 8回）\n",
    "混合モデルとEMアルゴリズム\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 担当教員: 梶野 洸（かじの ひろし）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "混合モデル\n",
    "\n",
    "- 混合モデルの導入（混合ガウスモデル）\n",
    "- EM アルゴリズムの導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合モデル\n",
    "複数の分布を混合したモデル\n",
    "\n",
    "$$\n",
    "p(X) = \\sum_{Z\\in\\mathcal{Z}}p(X \\mid Z) p(Z)\n",
    "$$\n",
    "\n",
    "- $p(X \\mid Z)$: 複数の分布（$Z\\in\\mathcal{Z}$ごとに異なる分布）\n",
    "- $p(Z)$: 混合割合\n",
    "- $p(X)$: 最終的に得られる分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例: 混合ガウスモデル\n",
    "有限個のガウス分布を混合したモデル\n",
    "\n",
    "$$\n",
    "p(X) = \\sum_{Z=1}^{K} p(X \\mid Z) p(Z)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align}\n",
    "p(X \\mid Z) &= \\mathcal{N}(X; \\mu_{Z}, \\Sigma_{Z})~(\\mu_Z\\in\\mathbb{R}^D, \\Sigma_{Z}\\in\\mathbb{S}_{+}^D)\\\\\n",
    "p(Z=k) &= \\pi_k~(k=1,\\dots,K)\n",
    "\\end{align}\n",
    "$$\n",
    "ここで $\\sum_{k=1}^K \\pi_k = 1$ が成り立つとする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例: 混合ガウスモデル\n",
    "有限個のガウス分布を混合したモデル\n",
    "\n",
    "$$\n",
    "p(X) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(X; \\mu_{k}, \\Sigma_{k})\n",
    "$$\n",
    "\n",
    "と書くことが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例: 混合ガウスモデル\n",
    "\n",
    "混合ガウスモデルは $K+1$ 個の確率分布で構成される\n",
    "\n",
    "- $\\mathrm{Categorical}(\\mathbf{\\pi})$, $\\pi\\in\\Delta^K$\n",
    "    - カテゴリカル分布（$K$面サイコロ）\n",
    "    - 各面 $k$ が出る確率が $\\pi_{k}$\n",
    "- $\\mathcal{N}(\\mu_k,\\Sigma_k)$ ($k=1,\\dots,K$): $K$個の異なる正規分布\n",
    "    - 平均 $\\mu_k$, 分散共分散行列 $\\Sigma_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例: 混合ガウスモデル\n",
    "2つの正規分布からなる GMM\n",
    "\n",
    "<img src=\"figs/gmm_example.png\" width=\"1024px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成モデルとしての説明\n",
    "確率変数 $X$ を生成する過程としても解釈できる\n",
    "\n",
    "<img src=\"figs/gmm.png\" width=\"1024px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成モデルとしての説明\n",
    "数式では以下のように書く\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Z &\\sim \\mathrm{Categorical}(\\mathbf{\\pi})\\\\\n",
    "X &\\sim \\mathcal{N}(\\pi_{Z}, \\Sigma_{Z})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一行目で$K$面サイコロを振って $Z$ の実現値（$k$とする）を得る\n",
    "- 二行目で $Z=k$ に対応する正規分布から $X$ の実現値を得る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合モデルを考える理由\n",
    "\n",
    "- 既知の確率分布を組み合わせて複雑な確率分布を表現できる\n",
    "    - 正規分布単体では単峰の分布しか表現できない\n",
    "    - 正規分布を重ね合わせると複数の山を表現できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 潜在変数$Z$からの知識発見\n",
    "    - 事後分布 $p(Z \\mid X=x)$ は、データ $x$ がどの分布から出てきたのかを表す\n",
    "    - クラスタリングのような効果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Red\">★</font>のデータ $X$ は $Z=1$ から生成されたっぽい\n",
    "<img src=\"figs/gmm_posterior.png\" width=\"1024px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここまでのまとめ\n",
    "\n",
    "- 混合モデルを使うと複雑な確率分布も表現できる\n",
    "- 正規分布を有限個混合したモデルとして、混合ガウスモデルがある\n",
    "- データが生成される過程として書くことができる\n",
    "- クラスタリングのような使い方ができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "\n",
    "次のGMMに従う確率変数 $X$ を生成し、ヒストグラムを書け\n",
    "\n",
    "- 混合数$K=2$, 次元$D=1$\n",
    "- $p(Z=0)=p(Z=1)=1/2$\n",
    "- $p(X\\mid Z=0) = \\mathcal{N}(X; -5, 1)$\n",
    "- $p(X\\mid Z=1) = \\mathcal{N}(X; 5, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def gmm_sampling(sample_size):\n",
    "    z_sample = np.random.binomial(n=1, p=0.5, size=(sample_size,))\n",
    "    x_sample = np.random.randn(sample_size)\n",
    "    return x_sample + 10.0 * z_sample - 5.0\n",
    "\n",
    "sample = gmm_sampling(10000)\n",
    "plt.hist(sample, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合ガウスモデルの推定\n",
    "\n",
    "- ここまでは確率モデルが与えられたときにそれをどう解釈するかを議論していた\n",
    "- データセット $\\mathcal{D} = \\{x_1,\\dots,x_N\\}$ が与えられた時、そのデータセットが従う GMM を推定するにはどうしたら良いか？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混合ガウスモデルの自由度\n",
    "\n",
    "- $K$個の正規分布の平均ベクトル、共分散行列\n",
    "- どの正規分布を選ぶか決める確率分布 $\\pi_k=p(Z=k)$ ($k=1,\\dots,K$)\n",
    "- 混合数$K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最尤推定で求まるもの\n",
    "混合数は求まらない\n",
    "\n",
    "- $K$個の正規分布の平均ベクトル、共分散行列\n",
    "- どの正規分布を選ぶか決める確率分布 $\\pi_k=p(Z=k)$ ($k=1,\\dots,K$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最尤推定\n",
    "\n",
    "$$\n",
    "\\theta^\\star = \\arg\\max_{\\theta\\in\\Theta}p(\\mathcal{D} ; \\theta)\n",
    "$$\n",
    "をパラメタの推定値とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各データの独立同分布性を仮定すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(\\mathcal{D}; \\theta) &= \\sum_{n=1}^N \\log p(x_n; \\theta)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの仮定では、 $p(x;\\theta) = \\sum_{z=1}^{K}p(x \\mid z;\\theta)p(z;\\theta)$ だったので、上式は、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N \\log \\left( \\sum_{z_n=1}^{K} p(x_n \\mid z_n; \\theta)p(z_n;\\theta)\\right)\\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最尤推定量は式(1)を最大化することで求まる。\n",
    "\n",
    "最大化の手法は二種類\n",
    "\n",
    "1. 勾配法で式(1)を直接最大化する\n",
    "1. EMアルゴリズムで最大化する（今回はこっち！）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation-maximization (EM) アルゴリズム\n",
    "隠れ変数があるモデルの最尤推定量を求めるアルゴリズム\n",
    "\n",
    "- 現状は各データの隠れ変数 $z_n$ もパラメタ $\\theta$ もわからない\n",
    "    1. $z_n$ が1つに決まれば $\\theta$ がわかる\n",
    "    1. $\\theta$ が1つに決まれば $z_n$ がわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- とりあえずどちらかを初期化して、1, 2 を繰り返せばいい感じの $z_n$, $\\theta$ が求まりそう\n",
    "    - 局所最適解が求まることが示せる\n",
    "    - （大域的最適解を求めるのはそもそも難しいので諦めている）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM アルゴリズムの利点\n",
    "\n",
    "- EステップとMステップが解析的に書ける\n",
    "    - 毎ステップで尤度が下がらないことが保証される\n",
    "    - 勾配法だと、ステップサイズによって尤度が下がることもある\n",
    "- より難しいモデルの推定にも同じようなアイデアが適用できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "\n",
    "1. $X_n$ の実現値だけでなく $Z_n$ の実現値も得られていた場合の最尤推定量 $\\theta^\\star$ を計算せよ\n",
    "    - $(x_n, z_n)$ が $p(x, z;\\theta)= \\pi_{z}\\mathcal{N}(x; \\mu_z, \\Sigma_z)$ という同時分布に従っている\n",
    "    - $-\\sum_{n=1}^{N}\\log p(x_n, z_n;\\theta)$ を $\\theta$ について最小化する\n",
    "1. $X_n$ の実現値だけでなく、パラメタ$\\theta^\\star$の値もわかっている場合の隠れ変数の事後分布を計算せよ\n",
    "    - $p(Z_n \\mid X_n=x_n; \\theta^\\star)$ を計算する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 答え\n",
    "\n",
    "1. $\\{(x_n, z_n)\\}_{n=1}^N$ が得られていた場合、$x_n, z_n$ の同時分布は、\n",
    "\n",
    "$$\n",
    "p(x_n, z_n; \\theta) = \\pi_{z_n} \\mathcal{N}(x_n; \\mu_{z_n}, \\Sigma_{z_n})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "-\\sum_{n=1}^{N}\\log p(x_n, z_n;\\theta) &= -\\sum_{n=1}^N  \\sum_{k=1}^K \\mathbb{1}[z_n=k]\\left(\\log\\pi_{k} + \\log\\mathcal{N}(x_n; \\mu_{k}, \\Sigma_{k})\\right)\\\\\n",
    "&=\\sum_{n=1}^N \\sum_{k=1}^K \\mathbb{1}[z_n=k]\\left(-\\log\\pi_{k} + \\dfrac{1}{2}(x_n - \\mu_{k})^\\top \\Sigma_{k}^{-1} (x_n - \\mu_{k}) + \\dfrac{D}{2}\\log 2\\pi + \\dfrac{1}{2}\\log\\det\\Sigma_{k}\\right)\\tag{2}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu_k$ についての最大化\n",
    "\n",
    "式(2)を$\\mu_k$で微分すると\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\mathbb{1}[z_n=k]\\Sigma_{k}^{-1}(x_n - \\mu_k)\n",
    "$$\n",
    "なので、$\\mu_k$の最尤推定量は\n",
    "$$\n",
    "\\mu_k^{\\star} = \\dfrac{\\sum_{n=1}^N \\mathbb{1}[z_n=k]x_n}{\\sum_{n=1}^N \\mathbb{1}[z_n=k]}\n",
    "$$\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Sigma_k$ についての最大化\n",
    "\n",
    "式(2)を$\\Sigma_k$で微分すると\n",
    "\n",
    "$$\n",
    "\\dfrac{1}{2}\\sum_{n=1}^N \\mathbb{1}[z_n=k]\\left(-\\Sigma_k^{-1}(x_n - \\mu_k)(x_n - \\mu_k)^\\top\\Sigma_k^{-1} + \\Sigma_k^{-1}\\right)\n",
    "$$\n",
    "\n",
    "なので、$\\Sigma_k$の最尤推定量は\n",
    "\n",
    "$$\n",
    "\\Sigma_k^\\star = \\dfrac{\\sum_{n=1}^{N}\\mathbb{1}[z_n=k](x_n - \\mu_k^\\star)(x_n-\\mu_k^\\star)^\\top}{\\sum_{n=1}^{N}\\mathbb{1}[z_n=k]}\n",
    "$$\n",
    "\n",
    "となる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\pi_k$ についての最大化\n",
    "\n",
    "$\\pi_k$ は $\\sum_{k=1}^{K}\\pi_k=1$ を満たす必要があるため、\n",
    "式(2)に$\\lambda \\left(\\sum_{k=1}^K \\pi_k - 1\\right)$を足したものを$\\pi_k$で微分して\n",
    "$$\n",
    "\\sum_{n=1}^N \\mathbb{1}[z_n=k]\\left(-\\dfrac{1}{\\pi_k^\\star}\\right) + \\lambda=0\n",
    "$$\n",
    "を解けば良い。\n",
    "$$\n",
    "\\lambda \\pi_k^{\\star} = \\sum_{n=1}^N \\mathbb{1}[z_n=k]\n",
    "$$\n",
    "を $k=1,\\dots,K$ で足すと\n",
    "$$\n",
    "\\lambda = N.\n",
    "$$\n",
    "よって、\n",
    "$$\n",
    "\\pi_k^{\\star} = \\dfrac{\\sum_{n=1}^N \\mathbb{1}[z_n=k]}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) $p(Z \\mid X; \\theta) \\propto p(X \\mid Z; \\theta)p(Z; \\theta)$ なので、\n",
    "\n",
    "$$\n",
    "p(Z_n \\mid X_n=x_n;\\theta^\\star) = \\dfrac{\\pi_{Z_n}^{\\star}\\mathcal{N}(x_n; \\mu_{Z_n}^{\\star}, \\Sigma_{Z_n}^{\\star})}{\\sum_{k=1}^K\\pi_{k}^{\\star}\\mathcal{N}(x_n; \\mu_{k}^{\\star}, \\Sigma_{k}^{\\star})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習まとめ\n",
    "\n",
    "$z_n$ が1つに決まっていると、\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N \\log \\left( \\sum_{z_n=1}^{K} p(x_n \\mid z_n; \\theta)p(z_n;\\theta)\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "の log のなかの足し算がなくなって、\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N \\left(\\log p(x_n \\mid z_n; \\theta) + \\log p(z_n;\\theta)\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "の最大化となるため、解析的に解ける。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM アルゴリズムの導出\n",
    "\n",
    "任意の分布 $q(z)$ について\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\left(\\sum_{z}p(x\\mid z; \\theta) p(z;\\theta)\\right)\n",
    "= \\log \\left(\\sum_{z}p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}q(z)\\right)\n",
    "\\geq \\sum_{z}q(z)\\log \\left(p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}\\right)\\\\\n",
    "= \\sum_{z}q(z)\\left(\\log p(x, z; \\theta) - \\log{q(z)}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "が成り立つことを利用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 証明（演習）\n",
    "\n",
    "- $f\\colon \\mathbb{R}^D \\rightarrow \\mathbb{R}$: 任意の凸関数\n",
    "- $x_1,\\dots,x_N\\in\\mathbb{R}^D$ : $f$ の定義域の任意の$N$点\n",
    "- $w_1,\\dots,w_N\\in[0,1]$ s.t. $\\sum_{n=1}^N w_n = 1$ : 任意の重み\n",
    "\n",
    "とする。\n",
    "\n",
    "$$\n",
    "f\\left(\\sum_{n=1}^N w_n x_n\\right)\\leq \\sum_{n=1}^N w_n f\\left(x_n\\right)\n",
    "$$\n",
    "を示せ (Jensenの不等式)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ヒント\n",
    "$f: \\mathbb{R}^{D}\\rightarrow\\mathbb{R}$ が凸関数 $\\Longleftrightarrow$ 任意の$x_1, x_2\\in\\mathbb{R}^D$, $w_1, w_2\\in[0,1]$ s.t. $w_1 + w_2=1$ について\n",
    "$$\n",
    "f(w_1 x_1 + w_2 x_2) \\leq w_1 f(x_1) + w_2 f(x_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N$ の時に成り立っているとして、$N+1$の時にも成り立つことを示す。\n",
    "$$\n",
    "\\begin{align}\n",
    "f\\left(\\sum_{n=1}^{N+1} w_n x_n\\right) &= f\\left(w_{N+1}x_{N+1} + \\sum_{n=1}^N w_n x_n\\right)\\\\\n",
    "&=f\\left(w_{N+1}x_{N+1} + (1-w_{N+1})\\sum_{n=1}^N {w_n}\\dfrac{x_n}{1-w_{N+1}} \\right)\\\\\n",
    "&\\leq w_{N+1}f(x_{N+1}) + (1-w_{N+1})f\\left(\\sum_{n=1}^N \\dfrac{w_n}{1-w_{N+1}}x_n\\right)\\\\\n",
    "&\\leq w_{N+1}f(x_{N+1}) + (1-w_{N+1})\\sum_{n=1}^N \\dfrac{w_n}{1-w_{N+1}}f\\left(x_n\\right)\\ \\ \\left(\\text{note that}\\sum_{n=1}^N \\dfrac{w_n}{1-w_{N+1}}=1\\right)\\\\\n",
    "&=\\sum_{n=1}^{N+1}w_n f(x_n)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再掲\n",
    "\n",
    "$\\log x$ は凹関数なので、任意の分布 $q(z)$ について\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\left(\\sum_{z}p(x\\mid z; \\theta) p(z;\\theta)\\right)\n",
    "= \\log \\left(\\sum_{z}p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}q(z)\\right)\n",
    "\\geq \\sum_{z}q(z)\\log \\left(p(x\\mid z; \\theta) \\dfrac{p(z;\\theta)}{q(z)}\\right)\\\\\n",
    "= \\sum_{z}q(z)\\left(\\log p(x, z; \\theta) - \\log{q(z)}\\right) \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "が成り立つ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMアルゴリズムの導出\n",
    "\n",
    "尤度（式(3)の左側）を最大化する代わりに尤度の下界（式(3)の右側）を最大化する:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\sum_{z_n}q(z_n)(\\log p(x_n, z_n; \\theta) - \\log q(z_n))\n",
    "$$\n",
    "\n",
    "- $q$ に関する最大化\n",
    "- $\\theta$ に関する最大化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $q$ を固定して $\\theta$ に関して最大化\n",
    "\n",
    "$$\n",
    "p(x_n, z_n; \\theta) = \\pi_{z_n} \\mathcal{N}(x_n; \\mu_{z_n}, \\Sigma_{z_n})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "-\\sum_{n=1}^{N}\\sum_{k=1}^K q(z_n=k)\\log p(x_n, z_n=k;\\theta) &= -\\sum_{n=1}^N \\sum_{k=1}^K q(z_n=k)\\left(\\log\\pi_{k} + \\log\\mathcal{N}(x_n; \\mu_{k}, \\Sigma_{k})\\right)\\\\\n",
    "&=\\sum_{n=1}^N \\sum_{k=1}^K q(z_n=k)\\left(-\\log\\pi_{k} + \\dfrac{1}{2}(x_n - \\mu_{k})^\\top \\Sigma_{k}^{-1} (x_n - \\mu_{k}) + \\dfrac{D}{2}\\log 2\\pi + \\dfrac{1}{2}\\log\\det\\Sigma_{k}\\right)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "式(2)で $\\mathbb{1}[z_n=k]$ を $q(z_n=k)$ に変えたやつだ！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よって\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_k^{\\star} &= \\dfrac{\\sum_{n=1}^N q(z_n=k)x_n}{\\sum_{n=1}^N q(z_n=k)}\\\\\n",
    "\\Sigma_k^\\star &= \\dfrac{\\sum_{n=1}^{N}q(z_n=k)(x_n - \\mu_k^\\star)(x_n-\\mu_k^\\star)^\\top}{\\sum_{n=1}^{N}q(z_n=k)}\\\\\n",
    "\\pi_k^{\\star} &= \\dfrac{\\sum_{n=1}^N q(z_n=k)}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\theta$ を固定して $q$ に関して最大化\n",
    "\n",
    "$q$ は $\\sum_{k=1}^K q(z_n=k)=1~(n=1,\\dots,N)$ を満たす $N\\times K$ 個の実数からなる。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\dfrac{\\partial}{\\partial q(z_n=k)}\\left(\\sum_{n=1}^{N}\\sum_{k=1}^K q(z_n=k)(\\log p(x_n, z_n=k; \\theta) - \\log q(z_n=k)) + \\sum_{n=1}^N\\lambda_n \\left(\\sum_{k=1}^K q(z_n=k) - 1\\right)\\right)\\\\\n",
    "=&\\log p(x_n, z_n=k;\\theta) - \\log q(z_n=k) - 1 + \\lambda_n = 0\n",
    "\\end{align}\n",
    "$$\n",
    "を解くと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "q(z_n=k) &= \\dfrac{p(x_n, z_n=k;\\theta)}{\\sum_{k=1}^K p(x_n, z_n=k;\\theta)} \\\\\n",
    "&= \\dfrac{\\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM アルゴリズム\n",
    "\n",
    "- $\\mu_k, \\Sigma_k, \\pi_k~(k=1,\\dots,K)$ を適当に初期化\n",
    "- 以下を繰り返す:\n",
    "    - E-step: for each $n=1,\\dots,N, k=1,\\dots,K$,\n",
    "    $$q(z_n=k)\\leftarrow \\dfrac{\\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}$$\n",
    "    - M-step: for each $k=1,\\dots,K$,\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\mu_k &\\leftarrow \\dfrac{\\sum_{n=1}^N q(z_n=k)x_n}{\\sum_{n=1}^N q(z_n=k)}\\\\\n",
    "\\Sigma_k &\\leftarrow \\dfrac{\\sum_{n=1}^{N}q(z_n=k)(x_n - \\mu_k)(x_n-\\mu_k)^\\top}{\\sum_{n=1}^{N}q(z_n=k)}\\\\\n",
    "\\pi_k &\\leftarrow \\dfrac{\\sum_{n=1}^N q(z_n=k)}{N}\n",
    "\\end{align}\n",
    "    $$\n",
    "    \n",
    "適当な終了条件で繰り返しをやめる\n",
    "\n",
    "- 尤度の増分が一定以下になった\n",
    "- パラメタの変化幅が一定以下になった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMアルゴリズムまとめ\n",
    "\n",
    "- 変分法を用いて尤度の下界を求めた\n",
    "    - $\\sum_{n=1}^{N}\\sum_{z_n}q(z_n)\\log p(x_n, z_n; \\theta)$ みたいな形を出したかった\n",
    "    - $q$ と $\\theta$ を交互に最適化するとそれぞれ解析的に解ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMアルゴリズムの実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "混合ガウスモデルの場合、\n",
    "\n",
    "- 内部状態\n",
    "- 欲しい命令\n",
    "\n",
    "は何か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一つの答え\n",
    "\n",
    "- 内部状態\n",
    "    - 正規分布の平均、分散共分散行列 $\\times K$個\n",
    "    - 重み $\\pi=\\begin{bmatrix}\\pi_1 &\\dots & \\pi_K \\end{bmatrix}$\n",
    "- 命令\n",
    "    - データを入力して、パラメタを最尤推定する\n",
    "    - データを入力して、各データの潜在変数を推定する（現状の内部状態を使って）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 他の答え\n",
    "補助的なものを持っていてもよい\n",
    "\n",
    "- 内部状態\n",
    "    - 正規分布の平均、分散共分散行列 $\\times K$個\n",
    "    - 重み $\\pi=\\begin{bmatrix}\\pi_1 &\\dots & \\pi_K \\end{bmatrix}$\n",
    "    - __混合数 $K$ を陽に持っておくと何かと便利__\n",
    "- 命令\n",
    "    - データを入力して、パラメタを最尤推定する\n",
    "        - __E ステップを実行する__\n",
    "        - __M ステップを実行する__\n",
    "        - __尤度を計算する__\n",
    "    - データを入力して、各データの潜在変数を推定する（現状の内部状態を使って）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 他の答え2\n",
    "内部状態として他のクラスのオブジェクトを持っていてもよい\n",
    "\n",
    "- 正規分布クラス\n",
    "    - 内部状態\n",
    "        - 平均\n",
    "        - 分散共分散行列\n",
    "    - 命令\n",
    "        - データを入力して、パラメタを最尤推定する\n",
    "        - データを入力して、尤度を計算する\n",
    "\n",
    "- GMM クラス\n",
    "    - 内部状態\n",
    "        - 正規分布オブジェクト $\\times K$個\n",
    "        - 重み $\\pi=\\begin{bmatrix}\\pi_1 &\\dots & \\pi_K \\end{bmatrix}$\n",
    "        - __混合数 $K$ を陽に持っておくと何かと便利__\n",
    "    - 命令\n",
    "        - データを入力して、パラメタを最尤推定する\n",
    "            - __E ステップを実行する__\n",
    "            - __M ステップを実行する__\n",
    "            - __尤度を計算する__\n",
    "        - データを入力して、各データの潜在変数を推定する（現状の内部状態を使って）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python での実装\n",
    "\n",
    "まずは正規分布クラスを実装してみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "\n",
    "正規分布クラスを実装せよ（以前の資料からコピペでOK）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Gaussian:\n",
    "    def __init__(self, dim):\n",
    "        '''コンストラクタ（みたいなもの）\n",
    "        オブジェクトを作るときに初めに実行される。\n",
    "        内部状態の初期化に使う\n",
    "        '''\n",
    "        self.dim = dim\n",
    "        '''\n",
    "        self = オブジェクトを指す。 self.dim は、オブジェクトの dim という変数を指す。\n",
    "        上の命令は、 self.dim に dim の値を代入することを表す\n",
    "        '''\n",
    "        self.set_mean(np.random.randn(dim)) # オブジェクトの mean という変数をランダムに初期化\n",
    "        self.set_cov(np.identity(dim))\n",
    "        \n",
    "    def log_pdf(self, X):\n",
    "        ''' 確率密度関数の対数を返す\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        log_pdf : array, shape (sample_size,)\n",
    "        '''\n",
    "        if X.shape[1] != self.dim: # 入力の形をチェックしています\n",
    "            raise ValueError('X.shape must be (sample_size, dim)')\n",
    "        return -0.5 * np.sum((X - self.mean) * (np.linalg.solve(self.cov, (X - self.mean).T).T), axis=1) \\\n",
    "            -0.5 * self.dim * np.log(2.0 * np.pi) - 0.5 * np.linalg.slogdet(self.cov)[1]\n",
    "\n",
    "    def fit(self, X):\n",
    "        ''' X を使って最尤推定をする\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "        '''\n",
    "        if X.shape[1] != self.dim: # 入力の形をチェックしています\n",
    "            raise ValueError('X.shape must be (sample_size, dim)')\n",
    "        self.set_mean(np.mean(X, axis=0))\n",
    "        self.set_cov((X - self.mean).T @ (X - self.mean) / X.shape[0])\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        ''' 現状のパラメタを使って `sample_size` のサイズのサンプルを生成する\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        sample_size : int\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        X : numpy.array, shape (sample_size, dim)\n",
    "            各行は平均 `self.mean`, 分散 `self.cov` の正規分布に従う\n",
    "        '''\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, size=sample_size)\n",
    "        \n",
    "    def set_mean(self, mean):\n",
    "        if mean.shape != (self.dim,):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        self.mean = mean\n",
    "    \n",
    "    def set_cov(self, cov):\n",
    "        if cov.shape != (self.dim, self.dim):\n",
    "            raise ValueError('input shape inconsistency')\n",
    "        if np.linalg.eigvalsh(cov)[0] <= 0:\n",
    "            raise ValueError('covariance matrix must be positive semidefinite.')\n",
    "        self.cov = cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "- GMM クラスの `__init__` を書いてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        self.gaussian_list = []\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm のオブジェクトができた\n",
    "gmm = GMM(2, 10)\n",
    "for each_gaussian in gmm.gaussian_list:\n",
    "    print(each_gaussian.mean)\n",
    "print(gmm.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以降、EMアルゴリズムでパラメタ推定をする `fit` を書きたい\n",
    "\n",
    "- `log_pdf`: 現在のパラメタを用いてサンプルの対数尤度を計算するメソッド\n",
    "- `e_step`: Eステップを実行するメソッド\n",
    "- `m_step`: Mステップを実行するメソッド\n",
    "\n",
    "の3つを実装し、これらを組み合わせて `fit` を書く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "\n",
    "- サンプルの対数尤度を計算するメソッド `log_pdf` を `GMM` に実装せよ\n",
    "    - 引数: `X`: サンプルサイズ$\\times$次元の行列\n",
    "    - 返り値: $\\begin{bmatrix}\\log p(x_1; \\theta) & \\dots & \\log p(x_N; \\theta)\\end{bmatrix}$ ($\\theta$は現在の内部状態を用いる)\n",
    "    $$\n",
    "    p(x_n; \\theta) = \\sum_{k=1}^K \\pi_{k} \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self. dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "            \n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        '''\n",
    "        ここで現在の内部状態での likelihood を計算する\n",
    "        \n",
    "        ** ヒント **\n",
    "        self.gaussian_list の各要素は Gaussian クラスのオブジェクト\n",
    "        各データの対数尤度を計算する log_pdf という命令が実装してあった\n",
    "        '''\n",
    "        return np.log(likelihood) # 対数尤度が欲しいので対数をとる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ヒント\n",
    "\n",
    "- `self.gaussian_list[0].log_pdf(X)` はサンプル `X` のデータそれぞれに対する対数尤度を計算する\n",
    "    - `X` が `sample_size` x `dim` とすると、返り値は長さ `sample_size` の配列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `self.weight[0]` は $p(z=0; \\theta)$ に対応する\n",
    "- `self.weight[0] * np.exp(self.gaussian_list[0].log_pdf(X))` は `np.exp(self.gaussian_list[0].log_pdf(X))` の各要素に `self.weight[0]` を掛けた値を返す\n",
    "    - `スカラー * 配列` と書くと、配列の各要素にスカラーを掛けてくれる（`numpy` の記法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self. dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(2, 10)\n",
    "gmm.log_pdf(np.random.randn(100, 2)) # とりあえず何か計算はできている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "- Eステップを実行するメソッド `e_step` を実装せよ\n",
    "    - 引数: データ `X`: `sample_size` $\\times$ `dim` の配列\n",
    "    - 出力: $q(z_n)$\n",
    "        - どのような形式で出力すべきか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $q(z_n)$ は $K$ 面サイコロだったので、$K$面サイコロの確率分布をデータの数だけ出力すれば良さそう\n",
    "    - $K=$ `n_components`\n",
    "-  `posterior`: `sample_size` $\\times$ `n_components` の配列として出力\n",
    "-  `posterior[n, k]` = $q(z_n=k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E-step: for each $n=1,\\dots,N, k=1,\\dots,K$,\n",
    "$$q(z_n=k)\\leftarrow \\dfrac{\\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n; \\mu_k, \\Sigma_k)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)\n",
    "\n",
    "    def e_step(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        posterior = np.zeros((sample_size, self.num_components))\n",
    "        '''\n",
    "        ここを埋める\n",
    "        \n",
    "        ** ヒント **\n",
    "        各 n について、分母は共通\n",
    "        1. 分子を先に計算して posterior に入れてしまう\n",
    "        2. posterior[n, :].sum() は分母と等しくなる\n",
    "        3. posterior[n, :] = posterior[n, :] / posterior[n, :].sum() とすれば良さそう\n",
    "        '''\n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "\n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)\n",
    "\n",
    "    def e_step(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        posterior = np.zeros((sample_size, self.num_components))\n",
    "        # 各コンポーネントで対数尤度が計算できるので、それを利用\n",
    "        for each_component in range(self.num_components):\n",
    "            posterior[:, each_component] \\\n",
    "               = self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        \n",
    "        # まとめて正規化しているが、 for 文でやってもOK（遅くなるけど）\n",
    "        posterior = posterior / posterior.sum(axis=1).reshape(-1, 1)\n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q はデータがどちらのコンポーネントに近いかを表しているので、\n",
    "# そんな感じの結果になって欲しい\n",
    "gmm = GMM(2, 2)\n",
    "X = gmm.gaussian_list[0].mean.reshape(1, 2)\n",
    "print(gmm.e_step(X))\n",
    "X = gmm.gaussian_list[1].mean.reshape(1, 2)\n",
    "print(gmm.e_step(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "- Mステップを実行するメソッド `m_step` を実装せよ\n",
    "    - 引数: データ `X`: `sample_size` $\\times$ `dim` の配列\n",
    "    - 出力: $q(z_n)$\n",
    "        - どのような形式で出力すべきか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, dim, num_components):\n",
    "        self.dim = dim\n",
    "        self.num_components = num_components\n",
    "        self.gaussian_list = []\n",
    "        self.weight = np.ones(self.num_components) / self.num_components\n",
    "        for _ in range(self.num_components):\n",
    "            self.gaussian_list.append(Gaussian(dim))\n",
    "    \n",
    "    def fit(self, X, eps=1e-8):\n",
    "        sample_size = X.shape[0]\n",
    "        converge = False\n",
    "        old_ll = -np.inf\n",
    "        new_ll = -np.inf\n",
    "        while not converge:\n",
    "            posterior = self.e_step(X)\n",
    "            self.m_step(X, posterior)\n",
    "            new_ll = self.log_pdf(X).sum()\n",
    "            if new_ll < old_ll:\n",
    "                raise ValueError('likelihood decreases!')\n",
    "            if np.abs(old_ll - new_ll) / np.abs(new_ll) < eps:\n",
    "                converge = True\n",
    "            old_ll = new_ll\n",
    "        return posterior\n",
    "    \n",
    "    def e_step(self, X):\n",
    "        posterior = np.zeros((X.shape[0], self.num_components))\n",
    "        for each_component in range(self.num_components):\n",
    "            posterior[:, each_component] \\\n",
    "               = self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        posterior = posterior / posterior.sum(axis=1).reshape(-1, 1)\n",
    "        return posterior\n",
    "    \n",
    "    def m_step(self, X, posterior):\n",
    "        self.weight = posterior.sum(axis=0)\n",
    "        for each_component in range(self.num_components):\n",
    "            self.gaussian_list[each_component].set_mean(posterior[:, each_component] @ X / self.weight[each_component])\n",
    "            self.gaussian_list[each_component].set_cov(\n",
    "                (posterior[:, each_component] * (X - self.gaussian_list[each_component].mean).T) \\\n",
    "                @ (X - self.gaussian_list[each_component].mean) / self.weight[each_component])\n",
    "        self.weight = self.weight / np.sum(self.weight)\n",
    "    \n",
    "    def log_pdf(self, X):\n",
    "        sample_size = X.shape[0]\n",
    "        likelihood = np.zeros(sample_size) # 各データの尤度を計算する\n",
    "        for each_component in range(self.num_components):\n",
    "            likelihood = likelihood + self.weight[each_component] * np.exp(self.gaussian_list[each_component].log_pdf(X))\n",
    "        return np.log(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((np.random.randn(100, 3), np.random.randn(100, 3) + 3))\n",
    "gmm = GMM(3, 2)\n",
    "posterior = gmm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gmm.gaussian_list[0].mean)\n",
    "print(gmm.gaussian_list[1].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
