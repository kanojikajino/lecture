{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"../custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 応用計量分析２（第13回）\n",
    "\n",
    "トピックモデルと変分ベイズ法\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 担当教員: 梶野 洸（かじの ひろし）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 概要\n",
    "\n",
    "1. トピックモデル（特に、Latent Dirichlet Allocation (LDA)）\n",
    "1. 変分ベイズ法による推論\n",
    "1. ~~実装~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルでやりたいこと\n",
    "文書集合が与えられた時に、 __トピック__ に応じて文書分類をしたい。\n",
    "\n",
    "- 文書1＝「台風24号が関東に接近します。最大風速は....」\n",
    "- 文書2＝「台風24号の影響で野球が中止に。」\n",
    "- 文書3＝「テニス選手の○○が全英オープンで初優勝しました。」\n",
    "- 文書4＝「○○教授がノーベル生理学・医学賞受賞。」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルの重要な仮定（1/3）\n",
    "\n",
    "トピックが異なると使われる単語が異なる。\n",
    "\n",
    "- 例1. 「テニス」という単語は、スポーツ記事以外ではあまり出現しない。\n",
    "- 例2. 「台風」という単語は、気象の記事以外ではあまり出現しない。\n",
    "- 例3. どのトピックでも出現する単語もある（「が」とか）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルの重要な仮定（2/3）\n",
    "\n",
    "ひとつの文書には複数のトピックが含まれうる\n",
    "\n",
    "- 文書1 = 天候100%\n",
    "- 文書2 = 天候50%、スポーツ50%\n",
    "- 文書3 = スポーツ100%\n",
    "- 文書4 = 科学100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルの重要な仮定（3/3）\n",
    "\n",
    "単語の順番は無視する\n",
    "\n",
    "- 単語の順序まで考えると難しすぎる\n",
    "- トピックを知る上では順番はそこまで重要じゃない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルのなんとなくの説明\n",
    "\n",
    "各トピックごとに異なる単語分布を持っている\n",
    "<img src=\"figs/word_dist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルのなんとなくの説明\n",
    "各文書はトピック分布で特徴付けられる\n",
    "<img src=\"figs/topic_dist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# トピックモデルのなんとなくの説明\n",
    "トピック分布からトピックを決め、そのトピックの単語分布から単語をサンプリングすることを繰り返して文書を作る。\n",
    "<img src=\"figs/word_gen.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 数学的な表現への準備\n",
    "データの表現\n",
    "- 文書集合 $w=\\{{w}_1,{w}_2,\\dots,{w}_M\\}$\n",
    "- 文書 $w_m = [w_{m,1}, \\dots, w_{m,N_m}]$, $(m=1,\\dots,M)$\n",
    "- 単語 $w_{m,n}\\in\\{1,\\dots,V\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 以下用いる記法\n",
    "添字が省略されている際には、その添字の範囲を全て含むベクトル・行列を表すものとする\n",
    "\n",
    "- $\\beta_{k,v}$ は $k=1,\\dots,K,\\ v=1,\\dots,V$ の範囲で定義されている\n",
    "    - $\\beta_{k} = \\begin{bmatrix}\\beta_{k,1} & \\beta_{k,2} & \\dots & \\beta_{k,V}\\end{bmatrix}$\n",
    "    - $\\beta = \\begin{bmatrix}\\beta_{1,1} & \\beta_{1,2} & \\dots & \\beta_{1,V} \\\\ \\beta_{1,1} & \\beta_{1,2} & \\dots & \\beta_{1,V}  \\\\ & & \\vdots & \\\\ \\beta_{K,1} & \\beta_{K,2} & \\dots & \\beta_{K,V} \\end{bmatrix}$\n",
    "    など"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 数学的な表現への準備（例）\n",
    "\n",
    "- 単語集合 $\\{1,\\dots,6\\}=\\{\\mathrm{a, is, dog, cat, walking, sleeping}\\}$\n",
    "- 文書1 ${w}_1=[\\mathrm{a, dog, is, walking}]=[1,3,2,5]$\n",
    "- 文書2 ${w}_2=[\\mathrm{a, cat, is, sleeping}]=[1,4,2,6]$\n",
    "- 文書集合 $w=\\{{w}_1, {w}_2\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# モデル（1/3）\n",
    "\n",
    "- 文書 $m$ のトピック分布のパラメタ $\\theta_m=\\begin{bmatrix}\\theta_{m,1} & \\dots & \\theta_{m,K}\\end{bmatrix}\\in\\Delta^{K-1}$\n",
    "    - ディリクレ分布に従う\n",
    "    - $\\theta_{m,k}\\geq0$,  $\\sum_{k=1}^K \\theta_{m,k} = 1~(m=1,\\dots,M)$ が必ず成り立つ\n",
    "$$\n",
    "\\begin{array}\n",
    "\\ &p(\\theta_{m} \\mid \\alpha) = \\mathrm{Dir}(\\theta_m; \\alpha) = \\dfrac{\\Gamma(\\sum_{k=1}^K \\alpha_k)}{\\prod_{k=1}^K\\Gamma(\\alpha_k)} \\prod_{k=1}^K \\theta_{m,k}^{\\alpha_k-1}~(\\alpha_k>0)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# モデル（2/3）\n",
    "\n",
    "- 文書 $m$ の $n$ 個目の単語に紐づくトピック $z_{m,n}\\in\\{1,\\dots,K\\}$\n",
    "    - パラメタ $\\theta_m$ のCategorical distributionに従う\n",
    "$$\n",
    "\\begin{array}\n",
    "\\ &p(z_{m,n}=k \\mid \\mathbf{\\theta}_m) = \\theta_{m,k}\\\\\n",
    "\\text{where} & \\sum_{k=1}^K \\theta_{m,k} = 1~(m=1,\\dots,M)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# モデル（3/3）\n",
    "\n",
    "- 単語数$=V$, トピック数$=K$.\n",
    "- 文書 $m$ の $n$ 個目の単語 $w_{m,n}\\in\\{1,\\dots,V\\}$\n",
    "    - その単語に紐づくトピック $z_{m,n}\\in\\{1,\\dots,K\\}$ で定まる、パラメタ $\\beta_{z_{m,n}}$ のCategorical distributionに従う\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "\\ & p(w_{m,n}=v \\mid z_{m,n}=k, \\beta) = \\beta_{k,v}\\\\\n",
    "\\text{where } &\\sum_{v=1}^V \\beta_{k,v} = 1~(k=1,\\dots,K)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 生成モデル的な説明\n",
    "\n",
    "1. トピックごとの単語分布 $\\beta_{k,v} = p(w_{m,n}=v \\mid z_{m,n}=k)$ $(k=1,\\dots,K, v=1,\\dots,V)$ を決める\n",
    "    - トピックが $k$ だった時に単語 $v$ が出る確率\n",
    "    - $V$ 次元の多項分布が $K$ 個ある\n",
    "1. 文書 $m$ に対し、トピック分布のパラメタ $\\theta_m\\sim\\mathrm{Dir}(\\alpha)$ を決める\n",
    "    - $\\theta_m\\in\\Delta^{K-1}$ は $K$ 次元ベクトルで、多項分布のパラメタ\n",
    "    - 文書 $m$ でのトピックの出やすさを決める\n",
    "1. 文書 $m$ の単語 $n$ のトピック $z_{m,n}\\sim\\mathrm{Categorical}(\\theta_m)$ を決める\n",
    "1. 文書 $m$ の単語 $n$ の単語 $w_{m,n}\\sim\\mathrm{Categorical}(\\beta_{z_{m,n}})$ を決める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# グラフィカルモデル\n",
    "<img src='figs/graphical_model.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 学習\n",
    "\n",
    "データ $w=\\{{w}_1,\\dots,{w}_M\\}$ が与えられた時、\n",
    "1. $\\alpha$, $\\beta_{k,v}~(k=1,\\dots,K,\\ v=1,\\dots,V)$ をデータから推定する（最尤推定）\n",
    "1. $\\alpha, \\beta$ 固定の上で潜在変数 $\\theta_{m}$, $z_{m,n}$ $(m=1,\\dots,M,\\ n=1,\\dots,N_m)$ を推定する（inference）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inference\n",
    "- $(\\alpha, \\beta)$ は固定\n",
    "- データ $w$ を与えた元での潜在変数 $(\\theta, z)$ の事後分布を推定したい\n",
    "$$\n",
    "p(\\theta, z \\mid w, \\alpha, \\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 事後分布は直接計算できない\n",
    "$$\n",
    "p(\\theta, z \\mid w, \\alpha, \\beta) = \\dfrac{p(\\theta, z, w \\mid \\alpha, \\beta)}{p(w \\mid \\alpha, \\beta)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "分子は計算できる\n",
    "$$\n",
    "p(\\theta, z, w \\mid \\alpha, \\beta) = \\prod_{m=1}^M \\left[ p(\\theta_m \\mid \\alpha) \\prod_{n=1}^{N_m} \\left[p(z_{m,n} \\mid \\theta_m) p(w_{m,n} \\mid z_{m,n}, \\beta)\\right]\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "分母は計算できない\n",
    "$$\n",
    "\\begin{align}\n",
    "p(w \\mid \\alpha, \\beta) &=\\prod_{m=1}^M \\int \\sum_{z} p(\\theta_m, z_m, w_m \\mid \\alpha, \\beta) \\mathrm{d}\\theta\\\\\n",
    "&= \\prod_{m=1}^M \\dfrac{\\Gamma(K\\alpha)}{\\Gamma(\\alpha)^K} \\int \\left(\\prod_{k=1}^K \\theta_k^{\\alpha-1}\\right) \\left( \\prod_{n=1}^{N_m} \\sum_{k=1}^K \\prod_{v=1}^V (\\theta_{m,k} \\beta_{k,v})^{w_{m,n}} \\right)\\mathrm{d}\\theta \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 事後分布の変分近似\n",
    "事後分布を以下の分布で近似する\n",
    "$$\n",
    "\\begin{align}\n",
    "q(\\theta, z \\mid \\gamma, \\phi) &= \\prod_{m=1}^{M} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)\\\\\n",
    "q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)&=q(\\theta_m \\mid \\gamma_m)\\prod_{n=1}^{N_m}q(z_{m,n} \\mid \\phi_{m,n})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- $q(\\theta_m \\mid \\gamma_m) = \\mathrm{Dir}(\\theta_m; \\gamma_m)$\n",
    "- $q(z_{m,n} \\mid \\phi_{m,n}) = \\mathrm{Categorical}(\\phi_{m,n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 事後分布の変分近似\n",
    "\n",
    "- 元のモデル: $\\theta_m$ と $z_m$ が従属\n",
    "- 変分分布: $\\theta_m$ と $z_m$ が独立\n",
    "    - 独立な場合は計算できることが多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 事後分布の変分近似\n",
    "事後分布との距離が近くなるように $\\gamma$ と $\\phi$ を学習する\n",
    "\n",
    "$$\n",
    "(\\gamma^\\star, \\phi^\\star) = \\arg\\min_{\\gamma, \\phi} \\mathrm{KL}(q(\\theta, z \\mid \\gamma, \\phi) || p(\\theta, z \\mid w, \\alpha, \\beta))\n",
    "$$\n",
    "ここで $q(\\theta, z \\mid \\gamma, \\phi) = \\prod_{m=1}^M q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 事後分布の変分近似（文書 $m$ ごとに）\n",
    "事後分布との距離が近くなるように $\\gamma_m$ と $\\phi_m$ を学習する\n",
    "\n",
    "$$\n",
    "(\\gamma_m^\\star, \\phi_m^\\star) = \\arg\\min_{\\gamma_m, \\phi_m} \\mathrm{KL}(q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) || p(\\theta_m, z_m \\mid w_m, \\alpha, \\beta))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 補題1\n",
    "以下の等式が成り立つ:\n",
    "$$\n",
    "\\mathrm{KL}(q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) || p(\\theta_m, z_m \\mid w_m, \\alpha, \\beta)) = \\log p(w_m \\mid \\alpha, \\beta) - \\mathbb{E}_{q_m} \\left[\\log p(w_m, z_m, \\theta_m \\mid \\alpha, \\beta)\\right] + \\mathbb{E}_{q_m} \\left[\\log q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)\\right]\n",
    "$$\n",
    "\n",
    "左辺は事後分布 $p(\\theta_m, z_m\\mid w_m,\\alpha, \\beta)$があって計算できないが、右辺は事後分布がないため計算できることが嬉しい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 証明\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(w_m \\mid \\alpha, \\beta) &= \\log \\int \\sum_{z_m} p(w_m, \\theta_m, z_m \\mid \\alpha, \\beta) \\mathrm{d}\\theta_m\\\\\n",
    "&=\\log \\int \\sum_{z_m} \\dfrac{p(w_m, \\theta_m, z_m \\mid \\alpha, \\beta)}{q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) \\mathrm{d}\\theta_m\\\\\n",
    "&\\geq \\int \\sum_{z_m} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) \\log \\left( \\dfrac{p(w_m, \\theta_m, z_m \\mid \\alpha, \\beta)}{q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)}\\right) \\mathrm{d}\\theta_m\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 証明\n",
    "また\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(w_m \\mid \\alpha, \\beta) = \\int \\sum_{z_m} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) \\log p(w_m \\mid \\alpha, \\beta) \\mathrm{d}\\theta_m\n",
    "\\end{align}\n",
    "$$\n",
    "なので、（左辺） - （右辺）は、\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\int \\sum_{z_m} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) \\log \\left( \\dfrac{q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)p(w_m \\mid \\alpha, \\beta)}{p(w_m, \\theta_m, z_m \\mid \\alpha, \\beta)}\\right) \\mathrm{d}\\theta_m\\\\\n",
    "=&\\int \\sum_{z_m} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) \\log \\left( \\dfrac{q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)}{p(\\theta_m, z_m \\mid w_m, \\alpha, \\beta)}\\right) \\mathrm{d}\\theta_m\\\\\n",
    "=& \\mathrm{KL}(q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) || p(\\theta_m, z_m \\mid w_m, \\alpha, \\beta))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 事後分布の変分近似（文書 $m$ ごとに）\n",
    "事後分布との距離が近くなるように $\\gamma_m$ と $\\phi_m$ を学習する\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(\\gamma_m^\\star, \\phi_m^\\star) &= \\arg\\min_{\\gamma_m, \\phi_m} \\mathrm{KL}(q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) || p(\\theta_m, z_m \\mid w_m, \\alpha, \\beta))\\\\\n",
    "&= \\arg\\max_{\\gamma_m, \\phi_m}\\left(  \\mathbb{E}_{q_m} \\left[\\log p(w_m, z_m, \\theta_m \\mid \\alpha, \\beta)\\right] - \\mathbb{E}_{q_m} \\left[\\log q(z_m, \\theta_m \\mid \\gamma_m, \\phi_m)\\right]\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 目的関数を分解する\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\mathbb{E}_{q_m} \\left[\\log p(w_m, z_m, \\theta_m \\mid \\alpha, \\beta)\\right] - \\mathbb{E}_{q_m} \\left[\\log q(z_m, \\theta_m \\mid \\gamma_m, \\phi_m)\\right]\\\\\n",
    "=& \\mathbb{E}_{q_m} \\left[\\log p(\\theta_m \\mid \\alpha)\\right] +  \\mathbb{E}_{q_m} \\left[\\log p(z_m \\mid \\theta_m)\\right] +  \\mathbb{E}_{q_m} \\left[\\log p(w_m \\mid z_m, \\beta)\\right] \\\\\n",
    "& -  \\mathbb{E}_{q_m} \\left[\\log q(\\theta_m \\mid \\gamma_m)\\right] -  \\mathbb{E}_{q_m} \\left[\\log q(z_m \\mid \\phi_m)\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# それぞれの項を計算してみる\n",
    "\n",
    "第一項\n",
    "$$\n",
    "\\begin{align}\n",
    " \\mathbb{E}_{q_m} \\left[\\log p(\\theta_m \\mid \\alpha)\\right] &=  \\mathbb{E}_{q(\\theta_m \\mid \\gamma_m)} \\left[\\log \\Gamma\\left(\\sum_{k=1}^{K}\\alpha_k\\right) - \\sum_{k=1}^K \\log\\Gamma(\\alpha_k) + \\sum_{k=1}^K (\\alpha_k - 1) \\log \\theta_{m,k}\\right]\\\\\n",
    "&= \\log \\Gamma\\left(\\sum_{k=1}^{K}\\alpha_k\\right) - \\sum_{k=1}^K \\log\\Gamma(\\alpha_k) + \\sum_{k=1}^K (\\alpha_k - 1) \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- $\\Psi$ は digamma 関数（gamma関数を一階微分したもの）\n",
    "- $\\mathbb{E}_{q(\\theta_m \\mid \\gamma_m)}[\\log \\theta_{m,k}]= \\Psi\\left(\\alpha_k\\right) - \\Psi\\left(\\sum_{k=1}^K \\alpha_k\\right) $ を利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 参考\n",
    "- Dirichlet 分布は指数分布族に属する\n",
    "    - 確率密度関数が $p(x \\mid \\eta) = h(x) \\exp\\left[\\eta^\\top T(x) - A(\\eta)\\right]$ とかけること\n",
    "    - $T(x) = \\begin{bmatrix} \\log \\theta_1 & \\dots & \\log \\theta_K \\end{bmatrix}$\n",
    "    - $A(\\eta) =  \\sum_{k=1}^K \\log\\Gamma(\\alpha_k) -\\log \\Gamma\\left(\\sum_{k=1}^K \\alpha_k \\right)$\n",
    "- 指数分布族では以下が成り立つことを利用\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{p(x\\mid \\eta)}\\left[T(x)\\right] &= \\int T(x) h(x) \\exp(\\eta^\\top T(x)) \\exp(-A(\\eta)) \\mathrm{d}x\\\\\n",
    "&=  \\int \\left(\\dfrac{\\partial}{\\partial \\eta} h(x) \\exp(\\eta^\\top T(x))\\right) \\exp(-A(\\eta)) \\mathrm{d}x\\\\\n",
    "&=  \\int \\dfrac{\\partial}{\\partial \\eta} \\left(\\left(h(x) \\exp(\\eta^\\top T(x))\\right) \\exp(-A(\\eta))\\right) -  \\left(h(x) \\exp(\\eta^\\top T(x))\\right) \\dfrac{\\partial}{\\partial \\eta}\\exp(-A(\\eta))\\mathrm{d}x\\\\\n",
    "&= 0 -  \\int \\left(h(x) \\exp(\\eta^\\top T(x))\\right) \\dfrac{\\partial}{\\partial \\eta}\\exp(-A(\\eta))\\mathrm{d}x =  \\dfrac{\\partial}{\\partial \\eta}A(\\eta)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# それぞれの項を計算してみる\n",
    "\n",
    "第二項\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{q_m} \\left[\\log p(z_m \\mid \\theta_m)\\right] &= \\mathbb{E}_{q_m}\\left[\\sum_{n=1}^{N_m} \\log p(z_{m,n} \\mid \\theta_m)\\right]\\\\\n",
    "&= \\mathbb{E}_{q(\\theta_m \\mid \\gamma_m)}\\left[ \\sum_{n=1}^{N_m} \\sum_{k=1}^K q(z_{m,n}=k \\mid \\phi_{m,n}) \\log p(z_{m,n}=k \\mid \\theta_m)\\right]\\\\\n",
    "&=\\mathbb{E}_{q(\\theta_m \\mid \\gamma_m)}\\left[ \\sum_{n=1}^{N_m} \\sum_{k=1}^K  \\phi_{m,n,k} \\log \\theta_{m,k}\\right]\\\\\n",
    "&=\\sum_{n=1}^{N_m} \\sum_{k=1}^K  \\phi_{m,n,k} \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# それぞれの項を計算してみる\n",
    "\n",
    "第三項\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{q_m} \\left[\\log p(w_m \\mid z_m, \\beta)\\right] &= \\sum_{n=1}^{N_m} \\mathbb{E}_{q(z_{m,n} \\mid \\phi_{m,n})} \\left[\\log p(w_{m,n} \\mid z_{m,n}, \\beta)\\right] \\\\\n",
    "&= \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\phi_{m,n,k} \\log p(w_{m,n} \\mid z_{m,n}=k, \\beta)\\\\\n",
    "&= \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\sum_{v=1}^{V} \\phi_{m,n,k} \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# それぞれの項を計算してみる\n",
    "\n",
    "第四項\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{q_m} \\left[\\log q(\\theta_m \\mid \\gamma_m)\\right] &= \\mathbb{E}_{q(\\theta_m \\mid \\gamma_m)} \\left[\\log \\Gamma\\left(\\sum_{k=1}^{K}\\gamma_{m,k}\\right) - \\sum_{k=1}^K \\log \\Gamma(\\gamma_{m,k}) + \\sum_{k=1}^K (\\gamma_{m,k} - 1) \\log \\theta_{m,k}\\right]\\\\\n",
    "&= \\log \\Gamma\\left(\\sum_{k=1}^{K}\\gamma_{m,k}\\right) - \\sum_{k=1}^K \\log \\Gamma(\\gamma_{m,k}) + \\sum_{k=1}^K (\\gamma_{m,k} - 1) \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# それぞれの項を計算してみる\n",
    "\n",
    "第五項\n",
    "$$\n",
    "\\begin{align}\n",
    " \\mathbb{E}_{q_m} \\left[\\log q(z_m \\mid \\phi_m)\\right] &= \\sum_{n=1}^{N_m} \\mathbb{E}_{q(z_{m,n} \\mid \\phi_{m,n})} \\left[\\log q(z_{m,n} \\mid \\phi_{m,n})\\right] \\\\\n",
    " &=\\sum_{n=1}^{N_m} \\sum_{k=1}^K \\phi_{m,n,k} \\log \\phi_{m,n,k}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# まとめると(文書$m$に関する)目的関数は...\n",
    "$$\n",
    "\\begin{align}\n",
    "&L_m(\\gamma, \\phi; \\alpha, \\beta) \\\\\n",
    "=& \\log \\Gamma\\left(\\sum_{k=1}^{K}\\alpha_k\\right) - \\sum_{k=1}^K \\log\\Gamma(\\alpha_k) + \\sum_{k=1}^K (\\alpha_k - 1) \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right) \\\\ \n",
    "&+ \\sum_{n=1}^{N_m} \\sum_{k=1}^K  \\phi_{m,n,k} \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right) \\\\\n",
    "&+  \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\sum_{v=1}^{V} \\phi_{m,n,k} \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}\\\\\n",
    "&- \\left( \\log \\Gamma\\left(\\sum_{k=1}^{K}\\gamma_{m,k}\\right) - \\sum_{k=1}^K \\log\\Gamma(\\gamma_{m,k}) + \\sum_{k=1}^K (\\gamma_{m,k} - 1) \\left( \\Psi(\\gamma_k) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\\right)\\\\\n",
    "&- \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\phi_{m,n,k} \\log \\phi_{m,n,k}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\phi$ に関する最大化（$\\gamma$ は固定）\n",
    "各 $m,n$ について $\\sum_{k=1}^K \\phi_{m,n,k} = 1$ のもとで最大化\n",
    "\n",
    "ラグランジアンは\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ &L_m(\\phi) \\\\\n",
    "=&\\sum_{n=1}^{N_m} \\sum_{k=1}^K  \\phi_{m,n,k} \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right) \\\\\n",
    "+&  \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\sum_{v=1}^{V} \\phi_{m,n,k} \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}\\\\\n",
    "-& \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\phi_{m,n,k} \\log \\phi_{m,n,k} + \\sum_{n=1}^{N_m}\\lambda_n \\left(\\sum_{k=1}^K \\phi_{m,n,k}-1\\right)\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\phi$ に関する最大化（$\\gamma$ は固定）\n",
    "$\\phi_{m,n,k}$ で微分すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ &\\dfrac{\\partial}{\\partial \\phi_{m,n,k}}L_m(\\phi) \\\\\n",
    "= &\\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) + \\sum_{v=1}^{V}  \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}- \\log \\phi_{m,n,k} - 1 + \\lambda_n=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\phi$ に関する最大化（$\\gamma$ は固定）\n",
    "整理すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi_{m,n,k} \\propto \\exp\\left[\\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) + \\sum_{v=1}^{V}  \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}\n",
    "\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\lambda_n$ は正規化に使われる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\gamma$ に関する最大化（$\\phi$ は固定）\n",
    "$\\gamma_{m,k}$ に関する項は\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&L_m(\\gamma) \\\\\n",
    "=& \\sum_{k=1}^K (\\alpha_k - 1) \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right) \\\\ \n",
    "&+ \\sum_{n=1}^{N_m} \\sum_{k=1}^K  \\phi_{m,n,k} \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right) \\\\\n",
    "&- \\left( \\log \\Gamma\\left(\\sum_{k=1}^{K}\\gamma_{m,k}\\right) - \\sum_{k=1}^K\\log\\Gamma(\\gamma_{m,k}) + \\sum_{k=1}^K (\\gamma_{m,k} - 1) \\left( \\Psi(\\gamma_k) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\gamma$ に関する最大化（$\\phi$ は固定）\n",
    "整理すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&L_m(\\gamma) \\\\\n",
    "=& \\sum_{k=1}^K \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k^\\prime=1}^K \\gamma_{m,k^\\prime}\\right) \\right) \\left(\\alpha_k - \\gamma_{m,k} + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\\right)  \\\\ \n",
    "&- \\left( \\log \\Gamma\\left(\\sum_{k=1}^{K}\\gamma_{m,k}\\right) - \\sum_{k=1}^K \\log\\Gamma(\\gamma_{m,k}) \n",
    "\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\gamma$ に関する最大化（$\\phi$ は固定）\n",
    "$\\gamma_{m,k}$ で微分すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\dfrac{\\partial}{\\partial \\gamma_{m,k}}L_m(\\gamma) \\\\\n",
    "= &- \\Psi(\\gamma_{m,k}) + \\Psi\\left(\\sum_{k^\\prime=1}^K \\gamma_{m,k^\\prime}\\right)\\\\\n",
    "&+  \\Psi^\\prime(\\gamma_{m,k})  \\left(\\alpha_k - \\gamma_{m,k} + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\\right) \\\\\n",
    "&-  \\Psi^\\prime\\left(\\sum_{k^\\prime=1}^K \\gamma_{m,k^\\prime}\\right)\\sum_{k=1}^K \\left(\\alpha_k - \\gamma_{m,k} + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\\right) \\\\\n",
    "&- \\Psi\\left(\\sum_{k^\\prime=1}^K \\gamma_{m,k^\\prime}\\right) + \\Psi(\\gamma_{m,k})\\\\\n",
    "=& \\Psi^\\prime(\\gamma_{m,k})  \\left(\\alpha_k - \\gamma_{m,k} + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\\right) \\\\\n",
    "&-  \\Psi^\\prime\\left(\\sum_{k^\\prime=1}^K \\gamma_{m,k^\\prime}\\right)\\sum_{k=1}^K \\left(\\alpha_k - \\gamma_{m,k} + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\\right) \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\gamma$ に関する最大化（$\\phi$ は固定）\n",
    "$\\Psi^\\prime$ の中身は忘れて係数を見ると、以下の$\\gamma$で勾配が0になる\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\gamma_{m,k} = \\alpha_k + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inference アルゴリズム\n",
    "\n",
    "1. $\\phi_{m,n,k}$, $\\gamma_{m,k}$ を初期化 $(m=1,\\dots,M,\\ n=1,\\dots,N_{m},\\ k=1,\\dots,K)$.\n",
    "1. 以下を収束するまで繰り返す\n",
    "    1. $$\\begin{align}\n",
    "    \\phi_{m,n,k} \\propto \\exp\\left[\\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) + \\sum_{v=1}^{V}  \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}\n",
    "\\right]\n",
    "    \\end{align}\n",
    "    $$\n",
    "    1. \n",
    "$$\n",
    "\\begin{align}\n",
    "\\gamma_{m,k} = \\alpha_k + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\alpha$, $\\beta_{k,v}~(k=1,\\dots,K,\\ v=1,\\dots,V)$ をデータから推定\n",
    "- 上の Inference アルゴリズムを使うと、対数尤度の最もタイトな下界が求まる\n",
    "- 下の式の右辺を $\\phi, \\gamma$ について最大化していた\n",
    "- 対数尤度の下界を $\\alpha, \\beta$ について最大化すれば尤度を大きくできそう？\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(w_m \\mid \\alpha, \\beta) \\geq \\int \\sum_{z_m} q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m) \\log \\left( \\dfrac{p(w_m, \\theta_m, z_m \\mid \\alpha, \\beta)}{q(\\theta_m, z_m \\mid \\gamma_m, \\phi_m)}\\right) \\mathrm{d}\\theta_m\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\beta$ に関する最大化\n",
    "下界の $\\beta$ に関する項 + ラグランジアンは、\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\beta) = \\sum_{m=1}^M \\sum_{n=1}^{N_m} \\sum_{k=1}^K \\sum_{v=1}^{V} \\phi_{m,n,k} \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v} + \\sum_{k=1}^K \\lambda_k \\left(\\sum_{v=1}^V \\beta_{k,v} - 1\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\beta$ に関する最大化\n",
    "$\\beta_{k,v}$で微分すると\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dfrac{\\partial}{\\partial \\beta_{k,v}}L(\\beta) = \\sum_{m=1}^M \\sum_{n=1}^{N_m} \\dfrac{1}{\\beta_{k,v}}\\phi_{m,n,k} \\mathbb{1}[w_{m,n} = v] + \\lambda_k\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\beta$ に関する最大化\n",
    "$\\beta_{k,v}$で微分すると\n",
    "$$\n",
    "\\begin{align}\n",
    "\\beta_{k,v} \\propto \\sum_{m=1}^M \\sum_{n=1}^{N_m} \\phi_{m,n,k} \\mathbb{1}[w_{m,n}=v]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\alpha$ に関する最大化\n",
    "下界の$\\alpha$に関する項は、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&L(\\alpha) \\\\\n",
    "=& \\sum_{m=1}^M \\left[\\log \\Gamma\\left(\\sum_{k=1}^{K}\\alpha_k\\right) - \\sum_{k=1}^K \\log\\Gamma(\\alpha_k) + \\sum_{k=1}^K (\\alpha_k - 1) \\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\alpha$ に関する最大化\n",
    "下界の$\\alpha_k$に関する勾配は、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\dfrac{\\partial}{\\partial\\alpha_k}L(\\alpha) \\\\\n",
    "=& M \\left(\\Psi\\left(\\sum_{k=1}^{K}\\alpha_k\\right) -  \\Psi(\\alpha_k) \\right) + \\sum_{m=1}^M\\left( \\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\alpha$ に関する最大化\n",
    "勾配=0は解けないので、勾配法で最大化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $\\alpha, \\beta$ の推定アルゴリズム\n",
    "\n",
    "1. $\\alpha_k$ $(k=1,\\dots,K)$, $\\beta_{k,v}$ $(k=1,\\dots,K,\\ v=1,\\dots,V)$ を初期化\n",
    "1. $\\phi_{m,n,k}$, $\\gamma_{m,k}$ を初期化 $(m=1,\\dots,M,\\ n=1,\\dots,N_{m},\\ k=1,\\dots,K)$.\n",
    "1. 以下を収束するまで繰り返す\n",
    "    1. 変分下界の更新（E-step）\n",
    "    $$\\begin{align}\n",
    "    \\phi_{m,n,k} &\\propto \\exp\\left[\\Psi(\\gamma_{m,k}) - \\Psi\\left(\\sum_{k=1}^K \\gamma_{m,k}\\right) + \\sum_{v=1}^{V}  \\mathbb{1}[w_{m,n} = v] \\log \\beta_{k, v}\n",
    "\\right]\\\\\n",
    "    \\gamma_{m,k} &= \\alpha_k + \\sum_{n=1}^{N_m} \\phi_{m,n,k}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    1. $\\beta$ の更新（M-step 1）\n",
    "$$\n",
    "\\begin{align}\n",
    "\\beta_{k,v} &\\propto \\sum_{m=1}^M \\sum_{n=1}^{N_m} \\phi_{m,n,k} \\mathbb{1}[w_{m,n}=v]\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "    1. $\\alpha$ の更新（M-step 2）\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\alpha_k &\\leftarrow \\alpha_k + \\eta \\dfrac{\\partial}{\\partial \\alpha_k} L(\\alpha)\n",
    "    \\end{align}\n",
    "    $$\n",
    "    を収束するまで繰り返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "livereveal": {
   "center": false,
   "controls": true,
   "progress": true,
   "scroll": true,
   "slideNumber": true,
   "start_slideshow_at": "selected",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
